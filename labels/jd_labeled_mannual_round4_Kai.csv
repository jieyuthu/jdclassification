description,y
"RTI is hiring a Research Data Scientist to support our Center for Health Data Analytics. This role will be located in any one of the following RTI locations: Waltham, MA; Research Triangle Park, NC; Washington, DC.

This role provides a unique opportunity for a candidate with strong analytic and healthcare data experience, and equally strong communication and strategic planning skills, to shape and strengthen RTI’s Center for Health Data Analytics (CHDA) public health and clinical informatics capabilities and project portfolio.

CHDA staff provide analytic development and statistical programming expertise to transform expanding and diversifying data sources into meaningful evidence. Our experienced team of over 40 research programmer/analysts identify, extract, structure and link complex, multi-source healthcare data to be analysis-ready, to address research questions across the population health and health services research spectrum.


We are expanding our analytic capabilities to build and support a portfolio of public health and clinical informatics projects, and to strengthen our natural language processing and predictive modeling capabilities. We are seeking candidates with technical, analytic, content and planning experience with the same, to shape and support this expansion.
Duties and responsibilities to include, but not limited to;

This role requires a blend of data and analytic expertise, coupled with strategic planning experience around business development, project portfolio development, and identifying/building cross-organizational collaborations.
About half to two-thirds of this role will include project contributions across an array of healthcare and informatics projects. Project work will include research question design, analytic plan development, and data analysis and model-building using traditional (e.g., claims) and emerging (e.g., semi- and unstructured EHR streams, wearables) healthcare data sources.
The remainder of this role will include working closely with the CHDA Director and other senior staff to contribute to strategic planning efforts to expand staff analytic capabilities around natural language processing and predictive modeling, and planning efforts to expand our portfolio of informatics projects requiring application of these capabilities.
This role will contribute to proposal writing, business development and client management, that will increase over time.
Required Education/Qualifications:

Masters degree or higher in biomedical informatics, epidemiology, biostatistics, quantitative social or natural sciences, public health and/or computer science.
Six or more years applied experience across the following technical, analytic, data and content areas:
Technical software/platform: one or more of: SAS, SQL, R, Python, Stata
Analytic: analytic file creation, natural language processing and analysis of semi- and unstructured clinical data, predictive modeling (traditional and machine learning)
Data: analysis and linkage of large, complex, transactional and relationally-structured healthcare data (e.g., insurance claims, EHR clinical/financial/event log, disease registry, consumer/patient wearables, etc), including semi-structured and free-text clinical data
Content: strong understanding of how and where healthcare data are created, their flow through various entities and systems, and effects of this on curating and analyzing these data for secondary-use purposes (e.g., research, population/public health surveillance); experience with medical coding systems and taxonomies (e.g., ICD-9/10, CPT, HCPCS, NDC)
Strong oral and written communication skills, with demonstrated history of: (Proposal writing, scope of work development, and other business development activities, Professional conference and/or journal contributions)
Ability to work creatively and flexibly in a team environment, with experience identifying and constructing multi-disciplinary, collaborative project teams to tackle novel analytic problems
Must be legally authorized to work in the United States and should not require now, or in the future, sponsorship for employment visa status.
Must have lived in the United States for at least 3 of the past 5 years.",0
"In order to be considered, you must apply via the following link. Please follow the link, and submit to our system.https://rew21.ultipro.com/REA1008/JobBoard/ListJobs.aspxRealty Income, The Monthly Dividend Company®, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in a professional environment in a company that encourages a work-life balance, make sure to apply today!As Realty Income’s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.Your Contribution to the Team IncludesPredictive AnalyticsBuild predictive analytics for use cases such as: Portfolio Management; Development; AcquisitionsWork with business teams to identify, develop and deliver new use cases over timePrioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of deliveryDeliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business usersEnsure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as neededInfrastructure for Predictive AnalyticsCreate the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)Oversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrityCoordinate with the IT team to buy or license required tools, data and feedsWork with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lakeDetermine how and when to take and store “snapshots” of data so that we can go back in time to test new models and approachesOrganizational RelationshipsWork closely with business teams, IT, internal audit and enterprise risk to define end products and processesCreate cross-functional working groups or teams as needed to initiate, approve or complete workUpdate the Investment Committee monthly or quarterly on key matters such as portfolio riskSupport business teams in the achievement of their objectives using predictive analytics toolsPerforms other duties as assigned.What You’ll Need to be SuccessfulPhD or advanced degree preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research3-5+ years of experience providing advanced analytics within a business settingPrior work experience within real estate or financial services is preferred, but not requiredProgramming experience in Python, Spark and SQL. Java/Scala is a plusExperience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDBHands-on experience in Microsoft Azure and Amazon EC2 cloud platformDemonstrated ability to design and implement ETL workflows across both Windows and Linux environmentsAbility to clearly communicate ideas, orally or via written communicationsMust be authorized to work for any employer in the US without restrictionIn order to be considered for employment, please make sure to follow the link at the top. Resumes emailed, will not be considered.In response to COVID-19, Realty Income has maintained our business operations and have open opportunities, yet made necessary adjustments to our hiring process. We are conducting all steps of the interview process in a virtual capacity. In response to California’s Stay at Home order and other states with similar provisions, our employees will continue to work remotely until these restrictions have been lifted and it is safe to work in an office again. Realty Income has endeavored to be adaptable and strategic in our capacity to maneuver in an unfamiliar situation, and we pride ourselves on our resilience. We immensely appreciate both your flexibility and consideration of Realty Income for employment.To all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job’s alias, Realty Income employees, or any company location. Realty Income is not responsible for any fees related to unsolicited resumes.Job Type: Full-timeBenefits:Health insuranceDental insuranceVision insuranceRetirement planPaid time offFlexible scheduleParental leaveSchedule:Monday to FridayWork Remotely:Temporarily due to COVID-19",1
"We are looking for a Senior Data Engineer to join our growing Software Engineering organization. As a member of our growing Data Engineering team, you’ll use cutting edge AWS technologies and leverage your experience with data and data technologies to build out our fast-growing data and analytics platform that serves both our internal team members and our customers. We’re looking for someone who is passionate about data, databases, and all things in between and can bring their experience around best practices and effective technology approaches for moving, assembling, and creating value with data within a cloud-based SaaS platform.
What you’ll be doing:
Develop ETL to populate data lake using Glue / Spark
Develop streaming data pipelines using Lambda, Python, and Amazon Kinesis
Create data extracts to support internal reporting, analytics, and machine learning initiatives
Develop, maintain, and support customer facing analytics data model, including data extracts and data API
Performance tuning and maintenance on ETL and streaming pipeline processes
Mentor other team members on best practices
Participate in team-based knowledge sharing opportunities and contributing to the overall growth of the collective knowledge of Total Expert’s Data Engineering team
Requirements
Enthusiasm to work within a startup where every day can be a new adventure
5+ years of experience developing with Big Data and data streaming technologies in a team-based environment
3+ years of experience with AWS data tools and technologies including Glue, Athena, S3, Lambda, and Redshift
2+ years Python experience
Experience building data warehouse dimensional models for ease of use and performance
Expert SQL knowledge
Bachelor’s degree in Computer Science, Software Engineering, Information Technology or related field
Team based Agile/Scrum development experience using tooling such as Jira, Git, etc.
Benefits
Big Company Benefits, Startup Lifestyle
We believe that living a balanced life leads to more creativity and productivity. Here’s what you and your family get for helping us build what’s next.
Physical Wellness:
Medical Coverage
Prescription Drug Coverage
Dental Coverage
Vision Coverage
Health Club Membership
Health Advocate Program
Flexible Time Off Program
Financial Wellness:
Health Savings Account Flexible Spending Accounts Disability Protection
Life & Voluntary Life Coverage Voluntary Benefits
Pet Insurance
401(k) Retirement Savings Plan
Employee Referral Bonus
Perks:
Lunch delivery stipend
Complimentary snacks and beverages
On-site, covered parking
Professional development opportunities, including training and educational conferences
Company and team outings, such as Twins games, boat rides, etc.
Monthly birthday and anniversary celebrations
About us:
At Total Expert, we strive for excellence, innovation and customer success in everything we do. We are determined to reimagine the way people and technology work together so that we can allow our customers to build more meaningful, human connections with their customers.
Simply put, we believe that we are all a part of building something awesome and are committed to creating a world-class team and culture to do it.
In 2019, Total Expert made the Inc. 500 list of fastest-growing companies in the country at spot #105 and was the second fastest-growing Minneapolis-based company on the list. In addition to being awarded a Top Workplace by the Minneapolis-St. Paul Star Tribune (2018, 2019), we have also been recognized as a HousingWire Tech100 and Minne Inno 50 on Fire award winner in 2019.",3
"Overview:

Wells Fargo technology teams drive innovation to create a more powerful and fulfilling financial experience for our customers and team members. You will join more than 24,000 team members supporting 95 billion transactions annually in 10 countries. Our career opportunities span the technology spectrum: advanced analytics, big data, information security, application development, cloud enablement, project management and more.

SUCCESS PROFILE

Check out the top traits we're looking for and see if you have the right mix. Additional related traits listed below.

Analytical
Detail-oriented
Insightful
Inventive
Problem Solver
Curious
Benefits

Wells Fargo wants to help you get more out of life and take care of things outside the office to make life a little easier. We provide:

Medical, Dental and Vision
Employer Matching 401(k)
Tuition Reimbursment
Maternity and Paternity Leave
Paid Time Off
Responsibilties
Job Description

Important Note: During the application process, ensure your contact information (email and phone number) is up to date and upload your current resume when submitting your application for consideration. To participate in some selection activities you will need to respond to an invitation. The invitation can be sent by both email and text message. In order to receive text message invitations, your profile must include a mobile phone number designated as “Personal Cell” or “Cellular” in the contact information of your application.
At Wells Fargo, we have one goal: to satisfy our customers’ financial needs and help them achieve their dreams. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience.
Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.
This role is a part of DMI’s Enterprise Analytics Team – the central analytics group tasked with solving high-impact business challenges and standing up cutting-edge analytical capabilities to be shared across Wells Fargo’s analytic community.
We are looking for a high performer to join our team and help us solve challenging and interesting business problems through rigorous data analysis and predictive modeling. In this foundational role, you will support Customer Genome program. This initiative is focused on creating analytically derived insights to inform development of personalized customer experience and marketing programs. As part of the core Customer Genome team, you will collaborate with other data scientists to generate innovative ideas, define analytical needs, create hypothesis, conduct data discovery, data wrangling, and exploratory data analysis, evaluate data quality, and prepare datasets for building statistical models and machine learning algorithms. You will also help training, testing and deploying machine learning models.
Key Responsibilities Include:
Extract, transform and load data from multiple databases, validate integrity and prepare modeling datasets.
Understand business context of the data and perform in-depth exploratory data analysis (EDA) and present data discovery results and findings with business partners and others
Provide recommendations to data scientists to support complex predictive modeling projects.
Respond to ad-hoc requests from business partners to conduct data analysis to identify/quantify opportunities or address specific business questions.
Utilize emerging analytical and programming techniques to explore internal and external unstructured and semi-structured data; recommend how these additional data sources can be used to enhance existing data and provide additional insight.
Work with complex databases, conduct in-depth research to gain domain knowledge about the data and identify data issues, and propose solutions to improve data integrity; perform other database-related analyses and projects as requested.
Data Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.

Required Qualifications

8+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 5+ years of experience in one or a combination of the following: reporting, analytics, or modeling
4+ years of SQL experience
4+ years of ETL (Extract, Transform, Load) Programming experience
5+ years of experience with data manipulation, cleansing, and transformation
4+ years of Hadoop experience
2+ years of Python experience
4+ years of Hadoop experience with Spark

Desired Qualifications

Extensive knowledge and understanding of research and analysis
Strong analytical skills with high attention to detail and accuracy
Excellent verbal, written, and interpersonal communication skills
Extensive knowledge and understanding of research and analysis
Excellent verbal, written, and interpersonal communication skills
Strong analytical skills with high attention to detail and accuracy
1 + years of machine learning experience

Other Desired Qualifications

Experience working with big data infrastructure and tools (e.g., Hadoop, Spark, Hive, H2O).
Strong programming skills using SQL, Python with ability to manipulate data for analytical purposes and conduct statistical data analysis.
Knowledge of statistical techniques (e.g., probability, multivariate data analysis, regression, PCA, time-series analysis) and experience using machine learning algorithms.
Exposure to deep learning model deployment will be plus
Exceptional analytical skills with high attention to detail and accuracy; strong acumen proactively diagnosing and resolving data issues to ensure accuracy and completeness.
Prior experience in a role requiring collaboration across multiple functions within an organization, ability to translate and summarize complex data into understandable, actionable information and recommendations.
Proven ability to drive each project to completion with minimal guidance while effectively managing multiple projects at a time, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment.




Disclaimer

All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.

Relevant military experience is considered for veterans and transitioning service men and women.

Wells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.

ENT FINANCE",3
"DISQO is a next generation consumer insights platform. We provide the highest quality consumer data to the world's largest market research agencies, analytics companies, and brands. We operate one of the world's largest true consumer insights panels. This data helps our clients understand user behavior, build better experiences, and make better decisions. We utilize cutting-edge technology and innovative, out-of-the-box strategies to collect and analyze insights which help shape the products and services of tomorrow.

This is a great opportunity to join a fun, exciting & highly motivated team and upgrade your skills while creating real impact. We use a modern tech stack and cloud infrastructure. We are not only looking for work experience, but rather the willingness to step up to challenges and the ability to learn quickly.

We believe the best software is written and managed by small teams that know how to make the impossible possible. We use agile software development techniques and modern tools to focus our efforts on solving our business goals. We use OKRs to track everything we do. We deliver early and often. We obsess over our code, architecture and infrastructure and we believe that these practices lead to higher quality products.

Check out the DISQO Developer Blog for the latest from our DISQOTECH team.

What you will do:

Leverage your software development and data engineering skills to impact our business by taking ownership of key projects requiring coding and data pipelines
Collaborate with product managers, software engineers and data engineers to design, implement, and deliver successful data solutions
Define technical requirements and implementation details for data solutions
Design, build and optimize performant databases, data models, integrations and ETL pipelines in RDBMS and NoSQL environments
Maintain detailed documentation of your work and changes to support data quality and governance
Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to the customers
Be an active participant and advocate of agile/scrum practices to ensure health and process improvements for your team

What you bring to the table:


5+ years of experience designing and delivering large scale, 24/7, mission-critical data pipelines and features using modern big data architectures
3+ years of Scala
3+ years of Spark
2+ years of experience with AWS data ecosystem (Redshift, EMR, Glue, Athena, ...)
Deep knowledge in various ETL/ELT tools and concepts, data modeling, SQL, query performance optimization
Experience with building stream processing applications using Kinesis or Kafka
Experience with workflow management tools (Airflow, Oozie, Azkaban, Luigi, etc.)
Comfortable working in Linux environment
Ability to thrive in an agile, entrepreneurial start-up environment

Benefits & Perks:

100% covered Medical/Dental/Vision for employee
Equity
Unlimited Vacation
Flexible work hours
Catered lunches 3x a week
Stocked pantry
Happy Hours
Onsite Fitness Program
Discounted Gym Membership
Quarterly Offsites
401K
Life Insurance
FSA
Paid Maternity/Paternity leave
Employee Assistance Program
Travel Assistance Program

DISQO is an equal opportunity employer
Recruiting firms that submit resumes to DISQO without first entering into a written contract will not be entitled to any compensation on candidates referred by that firm.

DISQO Developer",3
"Overview:
SOS International LLC (SOSi) is seeking a Data Scientist to join our team in Vienna, VA. The Data Scientist will be a SME in architecting complex analytic solutions from a multitude of multi-national “big data” sets on a variety of highly sensitive and complex data sets. Driving a comprehensive data collection and exploitation strategy that will address worldwide trinational issues. This person will be using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. Working with a wide range of stakeholders and functional teams. The Candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholder to imporve business outcomes.

Candidates must be technically adept to provide technical, strategic guidance to senior level database administrators and application developers in the creation and implementation of new databases, as well as the maintenance of major existing databases supporting evolving applications. Duties include leading and consulting to all levels of the organization on the design, development and implementation of logical database structures and classification schema; and developing policies and procedures to build, maintain and leverage the data model; provide technical, strategic guidance on the development of metadata tags, Document Type Definitions, and schemas using appropriate technologies for representation such as HTML and XML. Ensure that metadata and data standards and definitions will support both local business processes and system implementations thereof, and corporate requirements for sharing data.
Responsibilities:
Develop comprehensive Enterprise Data Collection and Exploitation Strategies that align with client transitional mission sets
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Develop and recommend data management policies, standards, practices and security measures to ensure effective and consistent data management operations.
Develop methods of ensuring that the data incompatibilities among systems are systematically eliminated, diagnose, isolate and expediently resolve complex problems pertaining to data infrastructure.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications:

Possess an active in scope Secret Clearance
10+ years professional experience in solutioning complex data solutions
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 10 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,
JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.
Display thorough knowledge of missions and needs, and considerable knowledge of Intelligence Community missions, needs, and information sharing requirements.
Possess knowledge of backup or archival software — Acronis Recovery Expert; Backup and archival software; Systems and data disaster recovery software; VERITAS NetBackup
Possess knowledge of database management system software — Database management software; Microsoft SQL Server; Quest Central; Sybase Replication Server.
Possess knowledge of development environment software — C; Microsoft Visual Basic; Prolog; Restructured extended executor REXX.
Possess knowledge of data modeling software; IBM Rational Data Architect; Visual Paradigm DB Visual ARCHITECT.
Possess knowledge of object or component oriented development software — Microsoft Visual C# .NET; Practical extraction and reporting language Perl; Sun Microsystems Java; Sybase PowerBuilder.
Preferred Qualifications:
Fluency in a foreign Language
Working Conditions:
Normal office working conditions with possible requirement to lift and/or move objects or packages of up to 25 lbs
Periods of non-traditional working hours including consecutive nights or weekends when necessary",3
"JOB SUMMARY
Responsible for maintaining scalable and reliable data pipelines that support data operations for Reporting, Analytics, Applications, and Data Science by gathering and processing raw data at scale. Delivers solutions by developing, testing, and supporting cloud-based streaming applications. Develops data set processes for data modeling, mining, and consumption.

MAJOR DUTIES AND RESPONSIBILITIES
Actively and consistently supports all efforts to simplify and enhance the customer experience.

Create and maintain scalable, reliable, consistent and repeatable pipelines that support data operations for Reporting, Analytics, Applications, and Data Science.

Gather and process real-time data at scale (including writing APIs, stream processing jobs, and aggregation jobs).

Expertly use cloud-based tools to ingest and process data.

Profile data to measure quality, integrity, accuracy, and completeness.

Manage life cycle of multiple data sources.

Increase speed to delivery by implementing workload/workflow automation solutions.

Interact with various stakeholders to understand their business needs, communicate project status and develop relationships to ensure satisfaction

Perform other duties as assigned.

REQUIRED QUALIFICATIONS
Skills/Abilities and Knowledge
Ability to read, write, speak and understand English
Ability to use a wide variety of open source technologies and cloud services
Strong coding experience using Scala or Java
Strong background in Linux/CentOS installation and administration
Strong knowledge in data storage that demonstrates knowledge of when to use a file system, relational database, or NoSQL variant
Strong experience with Spark or Hadoop/Hive
Experience receiving, converting, and cleansing big data
Ability to identify and resolve end-to-end performance, network, server, and platform issues
Attention to detail with the ability to effectively prioritize and execute multiple tasks
In-depth knowledge of Agile development methodologies

Education
Bachelor's degree in an engineering discipline or computer science

Related Work Experience
3-5 years of designing and building Scala or Java applications
2+ years of designing and building cloud native applications
2+ years of Linux/Unix/CentOS system admin
1+ year(s) of designing and building Kafka or Kinesis applications

WORKING CONDITIONS
Office environment",3
"The Data Analyst Associate performs tasks related to the design, implementation, support/maintenance, and enhancement of NU's enterprise, vendor and in-house developed applications. Documents functional requirements, analyzes requirements in the context of software and processes, develops and executes test plans, assists with and documents business process improvement efforts, and works with production issues. Completes content, process, and procedures for technical and functional system work that is low in complexity. Receives direction and oversight from senior staff.
Specific Responsibilities:
Strategic Planning
Participates with senior analysts, end users and peers to ensure that user requirements are gathered, analyzed, all gaps are documented, and all deliverables completed (adhering to approved methodology and documentation standards).
Participates with functional users and technical staff to determine best approaches, ensuring that approved solutions are implemented in a timely and correct fashion.
Administration
Contributes to the creation of accurate documentation of process, procedure, and system/application configuration.
Provides input into the creation and maintenance of test scripts, implementation project plans, roll out communications and training materials.
Identifies simple use cases.
Development
Provides input into test scripts and performs detailed testing for simple use cases to ensure that the implemented software functions correctly.
Participates in iterative feedback processes among users, developers, and analysts to ensure software functionality aligns with requirements.
Performance
Enters basic software configurations to meet user needs.
Collaborates with technical, reporting and application resources to analyze and resolve basic production issues in a timely manner.
Performs other duties as assigned.
Minimum Qualifications:
Successful completion of a full 4-year course of study in an accredited college or university leading to a bachelor's or higher degree in a major such as computer science, information technology, or related; OR appropriate combination of education and experience.
Preferred Competencies: (Skills, knowledge, and abilities)
Experience configuring or administering a Student Information System software package such as Salesforce, PowerSchool, eSIS, Infinite Campus, Genius SIS, or similar product.
Experience configuring or administering a Learning Management System (LMS) such as Schoology, Moodle, Canvas, Blackboard Learn or similar product.
Experience creating training or documentation materials and providing technical assistance to personnel in a K-12 or higher education setting.
Ability to create and quality check SQL database queries.
Advanced Excel skills.
Experience using or willingness to learn a data visualization software package such as Tableau.
Experience using or willingness to learn a statistical analysis software package such as SAS, STATA, or SPSS.",0
"Simpluris is a national class action settlement administrator established in 2007 with offices in Florida and California. We provide a suite of technology-based services to develop, execute and administer class action lawsuits from discovery through distribution. With a strong focus on customer service and utilizing proprietary systems and innovative solutions, Simpluris has built a first-rate reputation for handling cases. Our core values and our commitment to excellence drive our Mission in providing premium settlement administration services. We are a purpose driven company made up of an ever expanding team of purpose driven people.
The opportunity looks like this...
Simpluris seeks to grow its Data Analyst team in our Winter Park, Florida office. We are primarily looking for an individual with a naturally analytical and curious mind who can see past the surface and understand the depth and complexities of the various issues a particular problem possesses and whom can identify clear paths to solutions. They must be able to view a problem from multiple angles and aspects to understand the client's needs. Most of our data projects are presented in a word problem type format which must be read and the project requirements extrapolated out from. This position requires working with our project management team in receiving various types and sources of data, interpreting and developing data project requirements, and utilizing tools such as Python, Excel, and SQL to cleanse, transform, and perform calculations against data as necessary for internal and external systems. The ideal candidate will have advanced Microsoft Excel skills, some experience utilizing Python or SQL, flourishes in a team dynamic, and possesses a passion for efficient and real world data applications. This opportunity is best suited for the self-starter who enjoys solving problems and wishes to be part of a fast-paced environment where they might challenge themselves and expand their knowledge and experience.
Requirements
Here is what we need from you...
Proficiency in data manipulation using MS Excel (Pivot Tables, VLOOKUP, etc.), SQL (SELECT/JOIN), and/or Python (Pandas, NumPy)
Ability to succinctly explain and thoroughly document steps of data analysis
Ability to follow instructions / SOP’s and develop new SOP’s
Ability to self-manage and work independently as needed
Ability to communicate data issues effectively to non-technical users
Here is what you will be doing...
Perform data cleansing/de-duplication/merging/calculation/analysis
Deal with various forms and sources of data utilizing tools including Microsoft Excel, SQL, R & Python
Interpret and develop project data and calculation requirements
Identifying and developing improved processes and workflows
Prioritize, organize, and audit work effectively against deadlines
Interface with internal/external staff & clients (technical & non-technical) directly resolving issues with data
Skillsets we’re looking for...
Solid critical thinking, analytical, and problem solving abilities
Comfort with basic algebra, logic, and statistics
Strong interpersonal communication skills (both oral and written)
High proficiency (i.e. Power User) in Microsoft Excel with knowledge of VLOOKUP, pivot tables, and other advanced functions
Some experience with a programming language (e.g. SQL, C#, JavaScript) a plus
Python or R experience preferred
Ability to learn new tools and business processes quickly
Prior experience performing ETL (extract, transform, and load) functions a plus
Prior experience with reporting (e.g., SSRS) or dashboarding (e.g., PowerBI) a plus
Education with majors related to IT/MIS, accounting, math, or similar programs
Benefits
If you think you have what it takes, come join our growing team of purpose driven people! This is a full time, permanent position and compensation is dependent upon experience. We offer benefits such as medical, dental, vision, life insurance and 401k plus bonus opportunities. Please submit salary requirements along with resume.
This is who we are…
Find out more about Simpluris, our company, our people, and our culture here:
YouTube Simpluris Culture Video (https://youtu.be/8kQzzp-D8bs)
https://www.linkedin.com/company/simpluris-inc
https://www.facebook.com/simpluris/
At Simpluris, we live by a code and our code is defined through our core values. We are looking for those who can commit to and live by these values as those are the type of individuals who will be successful and thrive here. However, if you feel you don’t resonate with these values, or if you’re not able to engage at this level, we’re probably not a good fit for one another. We expect from ourselves and those who choose to join us to be accountable for themselves and perform at or above the same level we do.
We realize not everyone is ready for this level of engagement and appreciate the recognition by those who are honest to see this is the not right fit or place for them. But for those who can commit, we believe you would make an ideal candidate to join our team based on our following core values:
Simply Elevate – Elevate yourself & others. We are stronger together.
Be Responsive – Move & execute.
Deliver – Do what you say you’re going to do. Say what you mean & mean what you say.
Exude Passion – Find the greater purpose, fully commit and participate with passion.
Work Without Boundaries – See it, own it, solve it, do it. Success is everyone’s responsibility.
Solutions Driven – Go beyond the surface, seek to continually improve & refine.",0
"Strength Through Diversity
Ground breaking science. Advancing medicine. Healing made personal.

The Data Analyst II oversees activities related to data integrity, security and enhancement of the value of data. The Data Analyst II may direct the movement of data across multiple systems; oversee its validation and organization and make sure that data is available to appropriate people and systems within an organization. The Data Analyst II will also develop and execute reports that will be important assets of the practice as they continue to develop and evaluate a new model of care.

Roles & Responsibilities:
Work with the clinical and administrative staff of the practice to define data reporting needs
Develop analytic reports that are easily understandable by clinical and administrative staff
Use modeling techniques and tools in analyzing and specifying data structure
Implement best practices in data management to ensure the integrity of the data, the quality of data processes and deliver analyzable or analyzed data to a variety of internal and external clients of the affiliated practice
Maintain data integrity and completes data analysis as necessary
Complete data capture, data extraction and analysis
Develop, maintain or implement procedures for data entry, data cleaning, documentation and other administrative tasks
Document, implement, maintain or recommend operating methods to improve processing, distribution, data flow, collection, database editing procedures
May define parameters for file or space utilization
Work closely with IT management and staff
Access data in the Data Warehouse, as required
Assist clinical and administrative staff with queries, statistical analyses, reports and technical difficulties related to data retrieval
Design and write custom applications needed to ensure the database meets requirements for the entry, management and reporting of data
Identify and recommend solutions to data management issues
Maintain knowledge of the current regulations and technologies related to data management
Write and prepare manuscripts and other materials for internal and external audiences
Perform other related duties
Help to build and perpetuate a practice environment and culture of collaboration, respect, learning, flexibility and fun among all team members
Requirements:
Bachelor’s degree or equivalent education/work experience. Master’s degree in relevant field of study preferred
3 years of analytics experience including report development and database application/management experience, preferably in a large medical center or healthcare environment
Advanced knowledge of database applications / management, SQL and /or SAS. Knowledge of computer programming preferred
Excellent conceptualization, design and analytical skills
Excellent written and oral communication skills
Exceptional attention to detail and accuracy
Strength Through Diversity

The Mount Sinai Health System believes that diversity is a driver for excellence. We share a common devotion to delivering exceptional patient care. Yet we’re as diverse as the city we call home- culturally, ethically, in outlook and lifestyle. When you join us, you become a part of Mount Sinai’s unrivaled record of achievement, education and advancement as we revolutionize medicine together.

We work hard to acquire and retain the best people, and to create a welcoming, nurturing work environment where you can develop professionally. We share the belief that all employees, regardless of job title or expertise, can make an impact on quality patient care.

Explore more about this opportunity and how you can help us write a new chapter in our story!

Who We Are

Over 38,000 employees strong, the mission of the Mount Sinai Health System is to provide compassionate patient care with seamless coordination and to advance medicine through unrivaled education, research, and outreach in the many diverse communities we serve.

Formed in September 2013, The Mount Sinai Health System combines the excellence of the Icahn School of Medicine at Mount Sinai with seven premier hospital campuses, including Mount Sinai Beth Israel, Mount Sinai Beth Israel Brooklyn, The Mount Sinai Hospital, Mount Sinai Queens, Mount Sinai West (formerly Mount Sinai Roosevelt), Mount Sinai St. Luke’s, and New York Eye and Ear Infirmary of Mount Sinai.

The Mount Sinai Health System is an equal opportunity employer. We promote recognition and respect for individual and cultural differences, and we work to make our employees feel valued and appreciated, whatever their race, gender, background, or sexual orientation.

EOE Minorities/Women/Disabled/Veterans",0
"Gatestone & Co. is looking for an efficient, detail-oriented Data Analyst. The Data Analyst will be responsible for facilitating the issuance of letters and digital communications to consumers, in accordance to regulatory and client expectations.
Our ideal candidate is self-motivated and produces high-quality work. They are able to prioritize tasks appropriately and effectively, and handle multiple tasks at once, while maintaining strong follow-up skills to ensure all responsibilities are handled.
In this role you will:
Complete service requests as it relates to the creation of new letters and digital communications
Perform daily tasks relating to quality control and data validation
Demonstrate accuracy and thoroughness; look for ways to improve and promote quality; apply feedback to improve performance; monitor own work to ensure quality
Assist the Compliance Manager in the development of an effective record keeping system, including letter approvals, letter log, and inventory and regulatory requirements
Import/export data from text format into Excel and vice versa, while maintaining field-level integrity and data accuracy
Work closely with IT and other departments in regards to letter status, communications to consumers, etc.
Other duties as assigned

Who We Are
Founded in 1926, Gatestone is an industry leader providing exceptional outsourced Customer Contact Centre and Business Process Outsourcing (BPO) solutions to the world’s most respected organizations. Our clients are some of the world’s most respected organizations including Fortune 500 companies.
Started by Nicholas Wilson from humble beginnings, Gatestone has grown into a major global outsource provider with 10 fully-integrated sites located across North America, Latin American, Central America and Asia offering skill sets across multiple experience levels and languages. Still under original ownership, the company is supported by a long-tenured management team who provide unparalleled strategic leadership at all levels throughout the organization.

Benefits of Working at Gatestone
At Gatestone, we understand that our corporate success starts by attracting the right people, developing and mentoring those that show potential and taking steps to retain and promote our top performers.
We believe in our employees and invest in providing the best growth opportunities. Promotions at Gatestone are based on merit, past performance, and leadership potential. We recognize our top employees and help them succeed. We also have a full time Employee Engagement Specialist who ensures we have fun while working hard!
When you join Gatestone, you do more than join a company. You become part of a team of talented and self- driven individuals dedicated to bring success to the Company and their lives.
Be a part of an Awarding Winning Company.
Check us out in Instagram to see how much fun the Gatestone experience really is!
https://www.instagram.com/gatestonebpo
Skills Required:
An analytical thinker, able to synthesize complex or diverse information, collect and research data, use intuition and experience to complement data; able to manage specialized work efficiently with confidence and competence
A problem solver who identifies and resolves problems in a timely manner; gathers and analyzes information skillfully, uses reason even when dealing with emotional topics
Ability to read, analyze, and interpret corporate, compliance, and legal documentation, as needed
Detail oriented, well organized and has proven ability to work within stringent timeframes
Excellent verbal, written, listening, and interpersonal skills
Efficient with troubleshooting
Familiarity with ticketing systems

Qualifications:
2+ years in an administrative role
Proficient with Microsoft Office suite
Knowledge of AS400 is required
Ability to pass a background check and drug screen
High school diploma or GED is required",0
"About the Department of Pathology:
Comprised of extraordinary faculty and staff, our mission is to improve the diagnosis, treatment and basic understanding of human disease. We accomplish this through our clinical services, research, and training the future leaders in pathology and related fields. A major focus of clinical research in the Department continues to be the correlation of patient outcome and treatment response with the surgical pathologic diagnosis of human cancers. Everything we do is to provide the highest quality of pathology diagnostic services to the patients for whom we passionately care.

For more information about the department visit http://pathology.stanford.edu/


About the Position:
We are seeking a Research Data Analyst 1 to join the group of Dr. Mike Angelo at the Stanford Blood Center in the Department of Pathology. This Data Analyst will aid in the development of algorithms and software for analysis of highly-multiplexed imaging data generated by a next-generation IHC platform (Multiplexed ion beam imaging) housed in the Angelo lab. A strong background in analyzing biological imaging data is desired. The Data Analyst will play a key role in designing, building and maintaining the analytical pipelines used for routine image analysis in the lab. Additionally, the Data Analyst will develop new methods for image segmentation, object identification and phenotyping. In addition to these cross-project responsibilities, the Data Analyst will also be involved in individual project, assisting M.D.s and Biology Ph.D.s in their data analysis tasks. Must be a good team player.
Duties include:
Collect, manage and clean datasets.
Employ new and existing tools to interpret, analyze, and visualize multivariate relationships in data.
Create databases and reports, develop algorithms and statistical models, and perform statistical analyses appropriate to data and reporting requirements.
Use system reports and analyses to identify potentially problematic data, make corrections, and determine root cause for data problems from input errors or inadequate field edits, and suggest possible solutions.
Develop reports, charts, graphs and tables for use by investigators and for publication and presentation.
Analyze data processes in documentation.
Collaborate with faculty and research staff on data collection and analysis methods.
Provide documentation based on audit and reporting criteria to investigators and research staff.
Communicate with government officials, grant agencies and industry representatives.

Desired Qualifications:
Bachelor’s degree in Mathematics, Statistics, Computer Science or related field.
Research experience in computational biology desired; specifically in analysis of high-throughput, multiplexed data. Experience in designing data analysis pipelines is an advantage.
Experience in industry as software engineer is desired; specifically is generating graphical user interfaces.
Knowledge and experience in machine learning is highly desired; specifically application of deep learning to computer vision and image analysis.
Intimate knowledge with at least one of the following programming languages: Python/R/Perl/Matlab/Java/C/C++
The candidate should be able to work independently, be highly motivated, well organized, adaptable and work well within a highly interdisciplinary and international team. Good communication and interpersonal skills as well as fluent English are essential, as well as proficient computer skills (Mac and PC).
Education & Experience:
Bachelor's degree or a combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering.

Knowledge, Skills and Abilities:
Substantial experience with MS Office and analytical programs.
Strong writing and analytical skills.
Ability to prioritize workload.

Certification & Licenses:
None
Physical Requirements:
Sitting in place at computer for long periods of time with extensive keyboarding/dexterity.
Occasionally use a telephone.
Rarely writing by hand.

Working Conditions:
Some work may be performed in a laboratory or field setting.",0
"Junior Data Analyst
A content technology platform, Nativo helps advertisers create meaningful brand connections with consumers and empowers publishers with breakthrough monetization solutions. We're preparing the world for the age of content, where digital advertising is becoming a seamless, authentic, and helpful consumer experience.
We invite you to join us for an exciting and rewarding experience as a Junior Data Analyst. This role will assist the Campaign Operations team by providing analytic support through measuring the effectiveness of active and completed native advertising campaigns. This individual will collaborate with other internal departments to advance the capabilities provided by the Analytics team.
What you'll do:
Perform data cleansing/de-duplication/merging/calculation/analysis
Prepare spreadsheets and PowerPoint presentations for clients
Proactively identify potential gaps in data and take the initiative to resolve issues
Provide assistance in other areas of the department/company as needed
What you need:
1-year minimum work experience in campaign analytics
Proficient with Excel (Vlookups, pivot tables, chart visualizations, etc.)
Basic understanding of concepts in online campaign analytics or brand study measurement
Comfortable working with PowerPoint
Exceptional written and verbal communication skills and the ability to present analysis to various levels of management and staff.
Intellectual curiosity to enjoy problem-solving and ask the right questions to arrive at an insight
Excellent teamwork skills
Ability to work well without constant direction
Must enjoy working in a fast-paced entrepreneurial startup environment
BA/BS degree in Business, Marketing, or related field
What We Offer:
At Nativo, you make an immediate impact. Nativo is made up of smart, talented and driven people looking for other potential team members with the same attitude of innovation and excellence. We offer incredible opportunities to learn and work on projects that transform digital advertising. We offer a competitive compensation and benefits package that includes stock options, health coverage, employer-matched 401k, cutting edge work, and the opportunity to join a rapidly growing startup with a proven product.
About Nativo
Nativo empowers brands and publishers with the world's most advanced platform for content.
For brands, Nativo enables storytelling at scale with the largest native reach and reveals insights that unlock return-on-content. For publishers, Nativo enriches monetization with the most comprehensive platform for next-generation ad formats and breakthrough technology for accelerated webpages. Nativo's mission is to equip advertising for the age of content, improving the web experience and creating meaningful connections for today's digital consumer.
From the hands and minds of an amazing team, Nativo has engineered a platform that has been recognized as the best available in the market. Nativo is respected, well-funded, and is recognized as one of the top tech companies to work for. Nativo is well-positioned to play a vital role in forging the path of media and advertising in the coming years. The opportunity to join a team that is making a huge impact is now.
For information on what personal information Nativo collects and how we use it, please see our CCPA privacy notice: https://nativo1.box.com/s/a0j9eonmrveq3ot6mgldvy3jm4f0msu4

Emy7kIdKKf",0
"Req. ID: 180202
Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.
We are seeking motivated individual to join our machine learning and deep learning team. Your role is to maintain and use state-of-the-art deep learning algorithms and tools. The team products are high-performance computer vision algorithms, demonstrations, hardware, compilers.
Responsibilities include, but not limited to:
Build and maintain:
Deep learning frameworks, software and models to train neural networks models
Learning scripts and custom learning criterion, optimization modules
Dataset of images and videos
Dataset scripts
Web-optimized scripts for server-side processing
Validation scripts, measure dataset and model performance, and run them on Linux computer clusters
Build code for applied computer vision: saliency, tracking, detection, recognition, localization
Read literature, summarize results, and present results and innovations to the team
Reproduce and validate state-of-art models from papers and publications
Interact with customers, accept and review software and product requirements, satisfy requirements.
Minimum Qualifications:
MS/PhD in Computer Science, Computer Engineering, Electrical Engineering, Physics or related experience
Minimum 5+ years experience on computer vision, machine-learning and deep learning algorithms, including Deep, Convolutional, Recurrent Neural Networks
Experience writing and maintaining professional software using: C, C++, Python, PyTorch, TensorFlow, Caffe or similar deep learning framework
Leader in machine learning competitions, and international datasets
Deep knowledge of machine / deep learning literature, especially recent years after 2012
Open source contributions
State-of-art knowledge of at least one of these computer vision techniques: face-identification, tracking, localization, detection, recognition, saliency, video-processing, image embeddings, similar images, video summarization, language models for image and video description, openCV, etc.
Excellent presentation, written and verbal skills, proven by international level conference participation, acclaimed web blogging
Preferred Qualifications:
Award winner during PhD
Multiple international journal articles or conference presentations
Highly ambitious with forward-thinking and entrepreneurial aspirations
Background knowledge on parallel/heterogeneous programming (CUDA / OpenCL)
Background in Linux administration
Able to set up servers and clouds of servers
Experience in at least one area: text translation, speech recognition, text analysis, sentiment analysis
Experience with recurrent network or similar: RNN, LSTM, neural attention and associative memories
Experience in multimedia Linux software, libav, image and video compression / decompression, formats, processing with ffmpeg, libav and similar
Experience in embedded ARM setup, configuration and use: Raspberry Pi or similar
Graphic design, web design, CAD design
Artistic insights and abilities
About Us
As the leader in innovative memory solutions, Micron is helping the world make sense of data by delivering technology that is transforming how the world uses information. Through our global brands — Micron, Crucial and Ballistix — we offer the industry’s broadest portfolio. We are the only company manufacturing today’s major memory and storage technologies: DRAM, NAND, NOR and 3D XPoint™ memory. Our solutions are purpose built to leverage the value of data to unlock financial insights, accelerate scientific breakthroughs and enhance communication around the world.
Micron Benefits
Employee Rewards Program, Healthcare, Paid time off (Combined Sick and Vacation Time), Retirement savings plans, Paid maternity/paternity leave, Employee Assistance Program, Professional development training, Workplace wellness programs, Micron Health Clinic (Boise only), Fitness Center/Activity rooms (Boise/San Jose only), Tuition Reimbursement, Micron Corporate Discounts, Casual Dress attire.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.
For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s Human Resources Department at 1-800-336-8918 or 208-368-4748 and/or by completing our General Contact Form
Keywords: Seattle || Washington (US-WA) || United States (US) || DEG (DRAM Engineering Group) || Experienced || Regular || Engineering || #LI-BG1 || Tier 4 ||",2
"Data Analyst - Equinox Media
Overview

OUR STORY:
We are a company with integrated luxury and lifestyle offerings centered on Movement, Nutrition and Regeneration. In addition to Equinox, our other brands, Blink, Pure Yoga, SoulCycle, Furthermore, Precision Run and Equinox Hotels are all recognized for inspiring and motivating members and employees to maximize life. Within our portfolio of brands, we have more than 200 locations within every major city across the United States in addition to London, Toronto, & Vancouver.
Job Description

It is an exciting yet critical time for our teams at Equinox Media and we're looking for a Data Analyst to join our Data team to help us invent new ways of connecting people to the communities and fitness that they love. If you're someone who is passionate about developing strategies based on insights from real people and data, and can turn those insights into opportunities for the business and product teams to grow, then this is the team for you. There will also be significant exposure to modern data processing and analytic tools as your work spans across the broader technology groups as well. Our team embraces a true entrepreneurial spirit; operating with a sense of pride, perseverance and care for one another. We strive to continually deliver the best results and focus on how every action taken helps push our mission forward.
What you'll do:
Providing data reporting functions to the business and technical community using SQL
querying
Working with business and technology partners to build insightful analytical solutions
Troubleshooting data discrepancies along with resolving and clarifying them
Identifying areas where operational efficiency can be improved through enhanced
automation along with implementing those enhancements
Help engineering team with profiling and onboarding new datasets.
Develop automated data profiling and quality checks
Qualifications

Bachelor’s Degree Required. MIS / Computer Science / Engineering / Data Science
discipline
Expertise in SQL Server/ Redshift; SQL analytic capabilities (with 4+
Years hands on experience in SQL)
4+ Years working as a Data Analyst with a strong ability to analyze data and perform
root cause analysis
Ability to extract information from multiple databases using complex query statements
and advanced database tools
Organize, analyze and disseminate medium to large amount of information with great
attention to detail and accuracy
Knowledge of analytic tools like Tableau
Good exposure to Data Warehouse principles and basic understanding of data modeling
concepts and methodologies
Experience working with structured and semi-structured data (xml, json)
Experience working with ticketing and project management systems (Zendesk, Jira)
Strong documentation and communication skills
Creative, flexible, eager to learn, and able to work successfully in a multi-project,
deadline driven environment within Agile framework
Excellent written and verbal communication skills required
Any marketing tools (Adobe, Braze, CDP, ExactTarget) experience a plus
Additional Information

Equinox Media is an equal opportunity employer. We celebrate unique points of views & experiences across age, gender identity, race, sexual orientation, physical or mental ability & ethnicity in building the future of our digital business. We aren’t just a company; we’re a community vested in each other’s success. We value humility and a team approach at every level of the company. We want to inspire a workplace where individuals embrace their differences and similarities, where we are building products and experiences that inspire and improve people's lives.
See what we're up to: https://www.fastcompany.com/90386259/soulcycle-at-home-equinox-announces-streaming-fitness-platform-equipment",0
"Requisition ID: 103442
Job Level: Mid Level
Department: Business Management
Market: Corporate Home Office
Employment Type: Full Time

District Overview
Kiewit Data Services’ (KDS) mission is to make Kiewit the premier data-driven organization in our industry. To accomplish this, our projects and districts need to have the right data, of the right quality, with the right level of analysis, available to them at the right time. KDS is a cross functional organization with employees that have expertise in data, technology, support and operations backgrounds. Our core functions are data Quality, Governance, Enablement, Analytics and Data Science.

Location
This position will be based out of Omaha, NE.

Responsibilities
Perform financial forecasting, reporting, and operational metrics trackingAnalyze financial data and create financial models for decision supportReport on financial performance and prepare for regular leadership reviewsAnalyze past results, perform variance analysis, identify trends, and make recommendations for improvementsWork closely with the accounting team to ensure accurate financial reportingEvaluate financial performance by comparing and analyzing actual results with plans and forecastsGuide cost analysis process by establishing and enforcing policies and proceduresProvide analysis of trends and forecasts and recommend actions for optimizationRecommend actions by analyzing and interpreting data and making comparative analyses; study proposed changes in methods and materialsIdentify and drive process improvements, including the creation of standard and ad-hoc reports, tools, and Excel dashboardsIncrease productivity by developing automated reporting/forecasting toolsPerform market research, data mining, business intelligence, and valuation compsMaintain a strong financial analysis foundation creating forecasts and modelsProficiency with Microsoft Excel is mentioned in virtually any financial analyst job description; familiarity with data query/data management tools is extremely helpful (Access, SQL, Business Objects)

Qualifications
0-3+ years of business finance or other relevant experienceHigh proficiency in financial modeling techniquesStrong fluency with Excel formulas and functionsBA, BS, or B.Com degree required (Bachelor’s Degree in Accounting/Finance/Economics)Strong analytical and data gathering skillsGood business acumenMBAs are preferredProven work experience in a quantitatively-heavy roleFMVA or similar designations preferredStrong quantitative and analytical competencySelf-starter with excellent interpersonal communication and problem-solving skillsAdvanced knowledge of ExcelAbility to streamline functions and passion to learn and growStrong interpersonal skills, including written and oral communication skillsComfort dealing with ambiguity and the ability to work independentlyExperience working with, and presenting to, senior executivesExcellent communication and presentation skills; be comfortable interacting with executive-level managementStrong financial modeling experience
Key Responsibilities
• Grow financial performance through analysis of financial results, forecasts, variances, and trends
Create recommendations to be presented to management and executivesDevelop financial models to support valuation, planning, and forecastingAid in the capital budgeting and expenditure planning processesReconcile existing transactions through cross-referencing of incoming and outgoing dataConduct comparables analysis and market research to support internal financial analysisMaintain up-to-date technical knowledge of financial instruments, market conditions, and trends

We are an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",0
"We are looking for a Data Engineer to organize, manage, query, analyze terabytes of data from multiple different digital sources (mobile apps, websites, sensors). The ideal candidate has a passion for delving into data to help drive decision making in real-time for 180+ sports properties around the world.We are a 24/7/365 global sports entity, so a solid understanding and love of sports is highly recommended.We are looking for someone who...Thinks nothing is impossibleIs a tinkerer and implementor of big-data systemsHas a knack for data visualization to derive insightsIs equally comfortable with database systems and machine-learning algorithmsWhat you will be doing...Running analyses on terabytes of data that arise from digital assetsApplying machine-learning algorithms on data sets in order to cluster and segment themProviding insights from the data, to understand user behavior, predict user behavior, identify anomalies, and identify patternsBuilding, maintaining, and refining data dashboardsDriving new product development based on insights from the dataBe our MVP if you have...2 years+ of machine-learning experience with giant data-sets2 years+ of experience in data visualization techniques and best practices2 years+ of experience in working with Hadoop, Hive, Spark, and other big-data platforms2 years+ of experience with SQL, relational databases, NoSQL databases, including Postgres and Cassandra2 years+ of experience with Google Analytics, Firebase2 years+ of experience with AWS cloud services, such as EC2, EMR, RDS, Redshift2 years+ of experience in Java/C++/Python programmingExpert programmer and tinkerer, comfortable around operating systems, cloud computing, network protocolsWillingness to work in a high energy, fast-paced environmentStrong desire to learn and grow careerDegree in Computer Science/Engineering, with a heavy focus on machine-learning, data science, data engineering.Job Type: Full-timePay: $59,000.00 - $79,000.00 per yearBenefits:401(k)Dental InsuranceHealth InsurancePaid Time OffParental LeaveProfessional Development AssistanceRelocation AssistanceVision InsuranceSchedule:Monday to FridayWeekendsCOVID-19 considerations:To keep our employees as as safe as possible, we are working remotely and allowing new hires to begin their employment remotely, with the expectation that they will be able to relocate to Pittsburgh once it is safe to travel.Experience:machine-learning: 2 years (Required)SQL and relational database: 2 years (Required)Tableau: 2 years (Required)Hadoop/Hive: 2 years (Preferred)Java programming: 2 years (Required)Education:Bachelor's (Required)Location:Pittsburgh, PA 15206 (Required)Work authorization:United States (Required)Application Question:What is the largest data-set you have analyzed? And what techniques did you use to analyze it?Work Location:One locationCompany's website:www.yinzcam.comBenefit Conditions:Only full-time employees eligibleWork Remotely:Temporarily due to COVID-19",3
"Position Demographics
At the Regional Transportation District of Denver, CO (RTD) our mission is to meet our constituents' present and future public transit needs by offering safe, clean, reliable, courteous, accessible and cost-effective service throughout the District. We look for candidates to join our team in creating a legacy for current and future generations.
-
RTD is an equal employment opportunity employer. RTD is a Drug-Free Workplace.

The Immigration Reform and Control Act requires that verification of employment eligibility be documented for all new employees by the end of the third day of work.

The Regional Transportation District complies with the Americans with Disabilities Act (ADA), to provide reasonable accommodations for persons with disabilities.

RTD participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the Form I-9.

Description of Work
This position manages and supports activities related to developing, implementing and ensuring that reporting and document retention is in compliance with Federal Railroad Administrative Regulations, other regulatory requirements and internal Standard Operating Procedures.
Duties & Responsibilities
ESSENTIAL:

Develops and implements policies, business processes, strategies and procedures for document retention, and control to ensure compliance with organizational policies, relevant legislation, legal guidelines, Colorado Public Utilities Commission and Federal Railroad Administration Regulations and Reporting requirements.

Acts as the primary data analyst and ensures single document repository control for Configuration Management, Software Configuration Management, Safety and Security, Positive Train Control and Inspection Management as required for a FRA Regulated Railroad.

Serves as energy account manager and assists Senior Accountant to monitor, track, and audit traction power, signal, communication house energy usage, building power usage and billing and assists in forecasting departmental budget needs. Reports annually to the U.S. Department of Transportation National Transit Database (NTD).

Assists Safety and Security with NTD reporting for the Commuter Rail Network.

Analyzes information and evaluates results using logic and reasoning to identify the strengths and weaknesses of alternative solutions.

Assists in developing, planning and implementing FRA reporting structures, data reporting and retention as required, software and technical reporting improvements, training and resourcing staff concerning reporting management and organization. Ensures hours of service and other FRA retention reports are secured in the central repository.

Acts as liaison to Information Governance for internal document requests, CORA requests and provides support for Customer Care requests.

OTHER:

All job-related duties as assigned.
Qualifications
Bachelor's degree in Business Administration, Decision Science, Mathematics, Analytics, Engineering or a closely related field.

A minimum of four years of experience in records management or a document management environment.

A minimum of four years of experience with software such as Oracle, Aconex, RailDocs, Laserfiche or other reporting software,

A minimum of three years of experience in statistical analysis or data analysis with the ability to compile, code, categorize, calculate, tabulate, audit, and verify information and/or data and a minimum of two years of experience reporting and document retention in an FRA regulated railroad.

Knowledge of FTA/FRA/ADA/CPUC statutes, regulations, and laws associated with reporting and record management in an FRA regulated railroad preferred.

Ability to recognize information of a sensitive nature, and other issues requiring consultation with legal or escalation to subject matter experts.

Ability to work in a team environment and interpret the meaning of information for others by translating or explaining what the information means and how it is to be used.

Proficient with Microsoft Office Suite.

Ability to communicate effectively, orally and in writing.

Ability to use sound judgment.

Ability to manage time and workload effectively which includes planning, organizing, and prioritizing with attention to details.

OR:

An equivalent combination of education, experience, knowledge, skills, abilities.",0
"We are looking for a Senior Data Scientist to join our new Data Center and Networking AI Team to solve some of the hardest and most interesting technological challenges facing the industry today.
The Team
You will be joining a new team of world-class high-performing and low ego engineers and scientists that have an entrepreneurial and hacker spirit. The team will operate in a very self-driven, agile and fast-paced environment.
The team operates by self-organizing, around shared values, vision and objectives.
Keys to Hiring
You are the best candidate for this position if you are both mathematically inclined, self-motivated. You generate new ideas and initiatives to solve problems and identify trends and opportunities. You are comfortable working independently and figuring things out, and also enjoy working collaboratively in a small, fast-paced entrepreneurial environment. You enjoy being challenged and respectfully challenging others.
You write code almost every day and are comfortable working with your team to produce tools, pipelines, packages, modules, features, dashboards, or whatever is needed to move the team forward. You have a hacker’s spirit. You’re a quick study and technically flexible.
You have a strong ability to communicate about algorithms, complex data science methods, and statistical results to normal people in simple English using common ground, metaphors, and storytelling. You are intellectually curious, and enjoy looking at large data sets, to discover insights, and piece together stories. You like to develop a strong intuition to data by cleaning, organizing and labeling it. Other duties and responsibilities include, but are not limited to the following:
Build data pipeline to support data science needs
Build, test and deploy custom ML/AI models and algorithms on large datasets, and develop processes for monitoring and analyzing their performance on live mission critical environments
Drive innovation roadmaps to improve our machine learning models and experimentation techniques
Stay abreast with latest academic research to find best solutions for our use cases
Write or contribute to technical articles and white papers to showcase your work with visualizations to demonstrate ideas, challenges, algorithms, and results
Collaborate with academia and engineering/data science teams across companies and business units

Qualifications:
Ph.D. in Statistics, Computer Science, Machine Learning, Mathematics, Computational Psychology, Operational Research, Physics or relevant field
5+ years of most recent experience building models hands-on and track record of solving complex enterprise problems from scratch that went to production
Fluency in a programming language (Python, R, C, C++, Java)
Experience working with AI/ML technologies like TensorFlow, PyTorch, Keras, Caffe, scikit-learn, Spark MLlib and large-scale data sets and generating unique models and algorithms
Proficiency with analytical and database tools (e.g. Jupyter notebooks, Hive, Presto, SQL, No-SQL)
Strong background in classical machine learning and deep knowledge in a variety of techniques in feature selection, regression, classification, and clustering, and their real-world advantages and drawbacks
Domain knowledge of and hands-on experience building AI solutions for data centers, enterprise networks, WAN networks is a bonus",1
"WHAT WE'RE ABOUT

We're creating an airline people love. It begins with each Alaska Airlines employee, bringing unique strengths and energy to our work in the air and on the ground. Every day, we go beyond what's expected and reach for the remarkable, together.

YOUR ROLE

Role Summary

Become part of a dynamic environment that offers a hands-on internship experience. We are looking for talented and enthusiastic students to contribute toward key projects that support our business, community and cultural growth. Experience a work environment that thrives on innovation, collaboration and partnership.

Scope & Complexity

We want to talk to undergraduate students in their junior year who have accomplished outstanding academic results. The program is designed for a commitment of 40 hours per week for the duration of the 12-week program. When not working, we invite our interns to take advantage of unlimited complimentary space-available travel on Alaska Airlines or Horizon Air... Lunch in San Diego? Weekend in Portland? Maui? Phoenix... Done!

Key Duties

Build Azure Cloud based Azure Functions that read from Azure Service Bus and write data to a MongoDB based ODS and to an Azure Data Lake.

Build Python based integration tests.

Utilize established patterns and frameworks to develop deliverables.

Design JSON data structures suitable for key components in our enterprise ODS and data lake.

Work with a team of developers to define and produce deliverables.

Job-Specific Skills & Education

Required

Demonstrated ability to quickly learn a large number of new tools quickly.

Experience working with some or all of these: Azure Cloud Portal, Azure Functions, Azure Service Bus, JSON, MongoDB or MongoDB Atlas.

Experience coding with Python.

Experience working with Git source code control.

Internship positions are open to current undergraduate students in their junior year who are enrolled in a full time course of study graduating between December '20 and June '21.

High school diploma or equivalent is required.

Minimum age of 18.

Must be authorized to work in the U.S.

Preferred

Experience coding Azure Functions in Python using Visual Studio Code.

Experience setting up patterns and frameworks to enable building deliverables in a repeatable manner.

Demonstrated passion for producing top quality deliverables.

Job-Specific Leadership Expectations

Embody our values to own safety, do the right thing, be kind-hearted, deliver performance, and be remarkable.

START YOUR NEW JOURNEY NOW

Submit your application by 02/18/2020 11:59pm (Pacific Time). We'll be happy to see it.

EQUAL EMPLOYMENT OPPORTUNITY

Horizon Air and Alaska Airlines are equal opportunity employers. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, protected veteran or disabled status, or genetic information.

Horizon Air and Alaska Airlines will consider for employment qualified applicants with arrest and conviction records in accordance with applicable Federal, State, and local laws.

Horizon Air and Alaska Airlines participate in E-Verify, a service of the Department of Homeland Security (DHS) and Social Security Administration (SSA), where required.

Job ID 36195

Location Seattle, WA

FLSA Status Nonexempt",3
"Ultimate Software understands the value of data. The Data Engineering team is seeking a Cloud Data Engineer to help us extract this value. The team is responsible for all stages of data lifecycle management which includes capture, maintenance and publication. You will be responsible for designing, developing, testing, deploying and supporting data management solutions. This includes BI development, data pipeline (ETL/ELT) development, API data integrations, data quality and process monitoring/alerting.

Here at Ultimate Software, we truly put our people first. We strongly believe in teamwork, and we encourage and trust our people to reach higher, learn more, and live up to their potential. Ultimate is ranked #1 on Fortune's Best Places to Work in Technology for 2020 and #2 on the 100 Best Companies to Work For list in 2020. Ultimate is also ranked #2 on Fortune’s 75 Best Workplaces for Women and #9 on its Best Workplaces for Diversity list. Learn more about US here: www.ultimatesoftware.com/careers

Primary/Essential Duties and Key Responsibilities:

Design, develop and support database entities, data pipelines and processes required
for data integration (ETL/ELT)
Implement processes that ensure data quality, code quality, and the confidentiality of
all data
Possess the ability to learn emerging technologies quickly and apply them effectively
Design, implement, lead and manage large-scale, enterprise-wide and complex data
projects
Define and comply with internal development coding standards, procedural guides,
and checklists for the support of the data platform.
Provide in-depth troubleshooting skills to assist in resolving errors and performance
issues, including tier 2 production support
Understand business requirements, contribute to technical requirements and deliver
on time within a SCRUM methodology.


Required Qualifications:

6+ years with relational databases and SQL
3+ years data warehouse and ELT/ETL experience
2+ years programming with Python (Pandas and other common libraries)
2+ years object oriented programming experience
2+ years API integration experience
1+ year experience performing data integrations or data warehousing in a cloud data
platform, preferably Google Cloud


Preferred Qualifications:

Experience with data warehousing using Big Query in Google Cloud.
Experience with GCP Services - Cloud Dataflow, Cloud Firestore, Cloud Composer and Stackdriver.
A broad range of knowledge across Big Data, Azure, Data Vault, Tableau and other emerging technologies.

Education/Certification/License:

Bachelor’s Degree in Information Systems or related discipline preferred.


Travel Requirements:

Limited upon request


This job description has been written to provide an accurate reflection of the current job and to include the general nature of work performed. It is not designed to contain a comprehensive detailed inventory of all duties, responsibilities, and qualifications required of the employees assigned to the job. Management reserves the right to revise the job or require that other or different tasks be performed when circumstances change.

Ultimate Software will reasonably accommodate employees with disabilities as defined by the Rehabilitation Act of 1973, the Americans with Disabilities Act (ADA) and other appropriate statutes. If you are an applicant and need a reasonable accommodation when applying for job opportunities within the Company or request a reasonable accommodation to utilize the Company’s online employment application, please contact accessibility@ultimatesoftware.com.",3
"Named as one of Fortunes’ 100 Fastest Growing Companies for 2019, EPAM is committed to providing our global team of 30,100+ EPAMers with inspiring careers from day one. EPAMers lead with passion and honesty and think creatively. Our people are the source of our success and we value collaboration, try to always understand our customers’ business, and strive for the highest standards of excellence. No matter where you are located, you’ll join a dedicated, diverse community that will help you discover your fullest potential.


Description

You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Senior Big Dara Engineer. Scroll down to learn more about the position’s responsibilities and requirements.


EPAM Big Data Practice is looking for the Cloudera Big Data Engineers. As the Cloudera Data Engineer, you will be responsible for design and implement the management, monitoring, security and privacy of data using the full stack of Cloudera Hadoop Ecosystem services to satisfy the business needs.

#LI-DNI
#LI-DNP
What You’ll Do
Implement non-relational data stores:
Implement a solution that uses Hive, HBase, Impala DB, HDFS
Implement data distribution and partitions
Implement a consistency model in Hive/HBase
Provision a non-relational data store in HDFS
Provide access to data to meet security requirements
Implement for high availability, disaster recovery, and global distribution
Manage data security:
Implement data masking
Encrypt data at rest and in motion
Develop batch processing solutions:
Develop batch processing solutions by using Hive and Spark transformations
Ingest data by using Sqoop
Create linked services and datasets
Create oozie workflow pipelines and activities
Create and schedule jobs
Implement Cloudera Spark clusters, jupyter notebooks, jobs, and autoscaling
Ingest data into Cloudera HDFS
Develop streaming solutions:
Configure input and output with Kafka
Select the appropriate windowing functions
Implement event processing by using Spark Streaming /Kafka
Ingest and query streaming data using Spark
Monitor Cloudera Services:
Monitor Cloudera Cluster and its services like Spark, Oozie workflows, HDFS, Hive etc
Optimize Cloudera data solutions:
Troubleshoot data partitioning bottlenecks
Optimize HDFS Storage
Optimize Spark Streaming Analytics
Optimize Hive/Impala Analytics
Manage the data lifecycle
What You Have
5-10+ years in IT
2-3+ years in Cloudera and Hadoop Ecosystem
Experience in Agile or PMI methodology managed projects
Experience in enterprise applications, solutions and data infrastructures
Experience in designing of data management solutions
Experience in designing of robust CI/CD solutions
Python/PySpark (highly desired)
Java/Scala
Apache Hadoop HDFS, Map Reduce
Oozie
Hive
Cloudera Impala
Spark
Kafka
Spark Streaming
Yarn
Sqoop
Git, GitLab, Artifactory
ADO
Certifications:
SCRUM Developer
Big Data Hadoop certification
What We Offer
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance",3
"NO THIRD PARTY RESUMESJob Title: Data Analyst/Report Writer ILocation: Glendale Milwaukee WI 00001Duration: 6 Months Contact W2Description:Job Description: Transformation Data AnalyticsWhat you will doTransformation Data Analytics will be part of the Transformation Office reporting to the Transformation Office Director and Program Manager. You will apply your data engineering skills to solve real-life, complex problems and deliver long term sustainable impact. You will work with Transformation Program Management Team to set-up and execute a best in class Transformation Office and the related Performance Infrastructure. You'll build business, optimization, and financial models and deploy Transformation tools drawing upon various analytics techniques e.g., Excel, VBA, Tableau, SQL, Alteryx, Power BI, M, DAX etc. You will also enable best in class deployment of Transformation management tools and enable effective cadence planning, impact capturing, and program management. You will be responsible for database hygiene – providing quality control checks and proactively fixing issues; act as the primary point of contact for custom data requests, oversee any changes to the back end of the databases; and be responsible for regular database updates.How you will do itYou will work hand in hand with Transformation Office leadership, Workstream members, and Wave champions to ensure seamless delivery of dashboards and reports. Provide guidance and leadership to teams on analytics, build Workstream capabilities. Produce, maintain, and distribute the Transformation Office reports for all Workstreams. Conduct ad hoc analyses as requested, proactively searching for opportunities to deliver additional insights to members of the Transformation Office and Executive Committee. Be the first point of contact for Transformation participants with data questions. Have a complete understanding of the data and its structure, and provide coaching as necessary.Provide data and analytical support for the creation of financial and operational analyses supporting transformation and ongoing strategic plans and other documents.Required QualificationsUndergraduate or Graduate degree, preferably in Computer Applications, Engineering, Business Management, Mathematics, Operations researchStrong data modeling and data visualization skills across a range of platforms including 1) Excel and Excel VBA, 2) PostgreSQL or similar data engineering platforms, and 3) PowerBI (including DAX and M languages with at least 3 years of experienceExcellent analytical and problem-solving skills, including the ability to disaggregate issues, identify root causes and recommend solutionsKnowledge of fundamental business concepts, operations research and statistical techniquesDetail oriented and with ability to work under pressure, mentally resilient to endure the long and tough road of a transformationFlexibility, patience, and an understanding of fluid, demanding, and unstructured environments where priorities evolve constantlyHighly pragmatic, focused on achieving outcomes and impactEntrepreneurial and proactively thinking about potential improvements to how things are donePrevious work experience in building business algorithms, scenario planners, solving business problems using optimization techniques and running project management offices is preferredPassion for/attention to detailAbility to work effectively in a high pace environmentBasic software engineering project management experience in Agile, Lean, or Scrum development is a plus (in particular defining requirements, rapidly iterating and deploying features)Desires to accelerate their career path through a challenging and rewarding experiencePlease fill the details for Submission:Legal name:Contact no:Email id:Visa status:Current location:Relocation:Availability:End date of recent project:Linked in:Pay Rate Expected:Thanks&RegardsVenkat KothaTrigent Software Inc2 Willow Street, Suite #201 Southborough, MA 01745508-779-6728venkat_k @ trigent.comJob Type: ContractSalary: $29.00 to $35.00 /hourExperience:business analysis: 1 year (Preferred)data analyst: 1 year (Preferred)analytics: 1 year (Preferred)sql: 1 year (Preferred)data analysis: 1 year (Preferred)Benefits:None",0
"Category: Administrative/Staff

Department: Information Technology

Locations: Springfield, MA

Posted: May 4, 2020

Closes: Open Until Filled

Type: Full-time

Ref. No.: 2432


About American International College:
American International College is a private, coeducational institution of higher education located on a 70+ acre campus in Springfield, Massachusetts. The campus has 42 buildings on two sites approximately 1/2 mile apart with a total of approximately 660,000 gross square feet. Included in the inventory of buildings are student residences for a resident population of 900 students. Founded in 1885, the College has approximately 3200 graduate and undergraduate students. AIC offers a variety of undergraduate and graduate programs through the Schools of Business, Arts and Sciences; Health Sciences; and Education. The mission of the College is to transform student lives through career focused learning, with a strong foundation in the liberal arts, a commitment to serving the community, and a high level of involvement in the global economy.
AIC strives to create a diverse and inclusive campus community that is representative, at all job levels, of the students we serve. We are an EEO employer and we welcome applications from individuals for positions where they are underrepresented.

Job Description:
Develop, implement, and maintain systems to document and report on data
Work with and enhance data integration procedures, policies and publish to the College community via the Data Management Team
Create a strategy that will manage the data integrations environment and communications for College departmental and data management committee use.
Review and assist system and user documentation production by offices.
Continually analyze technologies, technical processes and/or functions as they relate to key performance metrics or executive dashboards.
Participate in data validation for regular internal and external reports and surveys
Support the ongoing assessment and effective utilization of data for planning, policy-making, and program improvement
Work with the College in defining key performance indicators
Produce statistics, analyses, reports, and reviews relative to internal and external requests for data
Compile, analyze, and disseminate quantitative data on facets of the College and related educational issues, including institutional characteristics, enrollments, student retention, student transfer activities, enrollment projections, grades, other student performance indicators and fiscal affairs

Requirements:
Required Degree(s): Bachelor's degree
Preferred Degree(s): Master's degree
Required Field of Expertise: Business Analytics, IT, Data Analytics; Minimum 5 years of experience in quantitative and qualitative research, statistical analysis, and reporting
Preferred Field of Expertise: Higher education
Knowledge/Skills/Abilities
Knowledge of current trends and issues relating to federal and state reporting; accreditation requirements; current and innovative practices in the development and assessment of institutional effectiveness and student learning outcomes; current theory and practice in institutional research; the development of assessment tools and methods of measurement; research design; data warehousing, management information systems
Ability to collaborate effectively with College offices and administration, seek consensus on outcomes, and apply bench-marking techniques.
Must possess excellent computer skills and familiarity with Higher Education Enterprise Systems and, SQL and data analysis software tools

Additional Information:
This is a full time, exempt level, benefit eligible position. Normal business hours are Monday through Friday, 8:30am - 4:30pm, flexible to the needs of the department. Night and weekend work may be required.

AIC is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

Application Instructions:
Qualified applicants should save and submit the following documents with the online application.
Brief cover letter
Current resume
Contact information for three professional references (one of which must be a current or prior supervisor)
Review of applications will continue until the position has been filled.",0
"Tripoint Solutions is seeking a Business Analyst with a strong data management background for a position located at our Huntsville, AL office.
This role is focused on maintaining operational data integrity, automated solutions, and visualizations for business processes reports. The Business Analyst will implement methods to evaluate the efficiency of complex data integrity, business operations, and software. You’ll work as part of a team with a highly engaged client that is focused on an environment of constant improvement and innovation. Proficiency in Oracle DB Server, MS SQL Server, Qlik Sense is required.
Job Location: Huntsville, AL
The successful candidate will be accountable to:

Conducting in-depth research and analysis of business and data management customer's needs.
Processes and systems for the company's support functions.
Analyzing possible technology solutions and assessing benefits, risks, costs, and technology architecture needs.
Assisting in planning and evaluating project activities including, project documentation, scheduling, requirements management, deployment readiness reviews, and status updates.
Participating in requirements gathering sessions, translating business requirements to detailed technical system specifications, and serving as the liaison amongst project stakeholders, customer, and team lead.
Participating in establishing quality standards for life cycle, documentation, requirement collection methods, testing, data quality analysis and reporting.
Research and content of business process planning and documentation.
Assisting in developing functional and non-functional software requirements.
Assisting in establishing quantitative measurements and techniques for measuring software quality.
Reviewing and evaluating software products and services for adherence to government directives, standards, and guidelines concerning software quality assurance.
Work closely with delivery managers to define, prioritize and solve complex business problems.
Creating data logic workflows, flowcharts, diagrams, and other documentation.
Creating, validating, and augmenting data management documentation on the configuration, infrastructure, and processes associated with the production environment (e.g., Oracle DB Server, MS SQL Server, etc) environment.
Deploying and testing database patches, maintenance jobs, and change scripts in non-production environments.
Proactively identifying tactical risks in the database environment and raise/resolve issues efficiently.
Required Skills
Data analysis and quality experience
Analytical ability
Ability to facilitate meetings and collaboration sessions with customer
Ability to quickly learn new concepts and software
Strong communication skills (both written and verbal)
Effectively communicate complex information
Proficiency in JIRA/ Confluence (Atlassian), MS Office Suite and G Suite (Docs, Drive, etc.).
Proficiency in Oracle DB Server, MS SQL Server, Qlik Sense
Experience, Education & Training:

Bachelor’s Degree with 2-4 years of experience. Or 7-9 years of experience in lieu of degree.
Proficiency in Oracle DB Server, MS SQL Server, Qlik Sense

Clearance Requirements
Applicants selected may be subject to a government security investigation and must meet eligibility requirements for potential access to classified information",0
