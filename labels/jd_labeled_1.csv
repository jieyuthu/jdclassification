description,y
"RTI is hiring a Research Data Scientist to support our Center for Health Data Analytics. This role will be located in any one of the following RTI locations: Waltham, MA; Research Triangle Park, NC; Washington, DC.

This role provides a unique opportunity for a candidate with strong analytic and healthcare data experience, and equally strong communication and strategic planning skills, to shape and strengthen RTI’s Center for Health Data Analytics (CHDA) public health and clinical informatics capabilities and project portfolio.

CHDA staff provide analytic development and statistical programming expertise to transform expanding and diversifying data sources into meaningful evidence. Our experienced team of over 40 research programmer/analysts identify, extract, structure and link complex, multi-source healthcare data to be analysis-ready, to address research questions across the population health and health services research spectrum.


We are expanding our analytic capabilities to build and support a portfolio of public health and clinical informatics projects, and to strengthen our natural language processing and predictive modeling capabilities. We are seeking candidates with technical, analytic, content and planning experience with the same, to shape and support this expansion.
Duties and responsibilities to include, but not limited to;

This role requires a blend of data and analytic expertise, coupled with strategic planning experience around business development, project portfolio development, and identifying/building cross-organizational collaborations.
About half to two-thirds of this role will include project contributions across an array of healthcare and informatics projects. Project work will include research question design, analytic plan development, and data analysis and model-building using traditional (e.g., claims) and emerging (e.g., semi- and unstructured EHR streams, wearables) healthcare data sources.
The remainder of this role will include working closely with the CHDA Director and other senior staff to contribute to strategic planning efforts to expand staff analytic capabilities around natural language processing and predictive modeling, and planning efforts to expand our portfolio of informatics projects requiring application of these capabilities.
This role will contribute to proposal writing, business development and client management, that will increase over time.
Required Education/Qualifications:

Masters degree or higher in biomedical informatics, epidemiology, biostatistics, quantitative social or natural sciences, public health and/or computer science.
Six or more years applied experience across the following technical, analytic, data and content areas:
Technical software/platform: one or more of: SAS, SQL, R, Python, Stata
Analytic: analytic file creation, natural language processing and analysis of semi- and unstructured clinical data, predictive modeling (traditional and machine learning)
Data: analysis and linkage of large, complex, transactional and relationally-structured healthcare data (e.g., insurance claims, EHR clinical/financial/event log, disease registry, consumer/patient wearables, etc), including semi-structured and free-text clinical data
Content: strong understanding of how and where healthcare data are created, their flow through various entities and systems, and effects of this on curating and analyzing these data for secondary-use purposes (e.g., research, population/public health surveillance); experience with medical coding systems and taxonomies (e.g., ICD-9/10, CPT, HCPCS, NDC)
Strong oral and written communication skills, with demonstrated history of: (Proposal writing, scope of work development, and other business development activities, Professional conference and/or journal contributions)
Ability to work creatively and flexibly in a team environment, with experience identifying and constructing multi-disciplinary, collaborative project teams to tackle novel analytic problems
Must be legally authorized to work in the United States and should not require now, or in the future, sponsorship for employment visa status.
Must have lived in the United States for at least 3 of the past 5 years.",1
"In order to be considered, you must apply via the following link. Please follow the link, and submit to our system.https://rew21.ultipro.com/REA1008/JobBoard/ListJobs.aspxRealty Income, The Monthly Dividend Company®, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in a professional environment in a company that encourages a work-life balance, make sure to apply today!As Realty Income’s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.Your Contribution to the Team IncludesPredictive AnalyticsBuild predictive analytics for use cases such as: Portfolio Management; Development; AcquisitionsWork with business teams to identify, develop and deliver new use cases over timePrioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of deliveryDeliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business usersEnsure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as neededInfrastructure for Predictive AnalyticsCreate the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)Oversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrityCoordinate with the IT team to buy or license required tools, data and feedsWork with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lakeDetermine how and when to take and store “snapshots” of data so that we can go back in time to test new models and approachesOrganizational RelationshipsWork closely with business teams, IT, internal audit and enterprise risk to define end products and processesCreate cross-functional working groups or teams as needed to initiate, approve or complete workUpdate the Investment Committee monthly or quarterly on key matters such as portfolio riskSupport business teams in the achievement of their objectives using predictive analytics toolsPerforms other duties as assigned.What You’ll Need to be SuccessfulPhD or advanced degree preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research3-5+ years of experience providing advanced analytics within a business settingPrior work experience within real estate or financial services is preferred, but not requiredProgramming experience in Python, Spark and SQL. Java/Scala is a plusExperience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDBHands-on experience in Microsoft Azure and Amazon EC2 cloud platformDemonstrated ability to design and implement ETL workflows across both Windows and Linux environmentsAbility to clearly communicate ideas, orally or via written communicationsMust be authorized to work for any employer in the US without restrictionIn order to be considered for employment, please make sure to follow the link at the top. Resumes emailed, will not be considered.In response to COVID-19, Realty Income has maintained our business operations and have open opportunities, yet made necessary adjustments to our hiring process. We are conducting all steps of the interview process in a virtual capacity. In response to California’s Stay at Home order and other states with similar provisions, our employees will continue to work remotely until these restrictions have been lifted and it is safe to work in an office again. Realty Income has endeavored to be adaptable and strategic in our capacity to maneuver in an unfamiliar situation, and we pride ourselves on our resilience. We immensely appreciate both your flexibility and consideration of Realty Income for employment.To all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job’s alias, Realty Income employees, or any company location. Realty Income is not responsible for any fees related to unsolicited resumes.Job Type: Full-timeBenefits:Health insuranceDental insuranceVision insuranceRetirement planPaid time offFlexible scheduleParental leaveSchedule:Monday to FridayWork Remotely:Temporarily due to COVID-19",3
"We are looking for a Senior Data Engineer to join our growing Software Engineering organization. As a member of our growing Data Engineering team, you’ll use cutting edge AWS technologies and leverage your experience with data and data technologies to build out our fast-growing data and analytics platform that serves both our internal team members and our customers. We’re looking for someone who is passionate about data, databases, and all things in between and can bring their experience around best practices and effective technology approaches for moving, assembling, and creating value with data within a cloud-based SaaS platform.
What you’ll be doing:
Develop ETL to populate data lake using Glue / Spark
Develop streaming data pipelines using Lambda, Python, and Amazon Kinesis
Create data extracts to support internal reporting, analytics, and machine learning initiatives
Develop, maintain, and support customer facing analytics data model, including data extracts and data API
Performance tuning and maintenance on ETL and streaming pipeline processes
Mentor other team members on best practices
Participate in team-based knowledge sharing opportunities and contributing to the overall growth of the collective knowledge of Total Expert’s Data Engineering team
Requirements
Enthusiasm to work within a startup where every day can be a new adventure
5+ years of experience developing with Big Data and data streaming technologies in a team-based environment
3+ years of experience with AWS data tools and technologies including Glue, Athena, S3, Lambda, and Redshift
2+ years Python experience
Experience building data warehouse dimensional models for ease of use and performance
Expert SQL knowledge
Bachelor’s degree in Computer Science, Software Engineering, Information Technology or related field
Team based Agile/Scrum development experience using tooling such as Jira, Git, etc.
Benefits
Big Company Benefits, Startup Lifestyle
We believe that living a balanced life leads to more creativity and productivity. Here’s what you and your family get for helping us build what’s next.
Physical Wellness:
Medical Coverage
Prescription Drug Coverage
Dental Coverage
Vision Coverage
Health Club Membership
Health Advocate Program
Flexible Time Off Program
Financial Wellness:
Health Savings Account Flexible Spending Accounts Disability Protection
Life & Voluntary Life Coverage Voluntary Benefits
Pet Insurance
401(k) Retirement Savings Plan
Employee Referral Bonus
Perks:
Lunch delivery stipend
Complimentary snacks and beverages
On-site, covered parking
Professional development opportunities, including training and educational conferences
Company and team outings, such as Twins games, boat rides, etc.
Monthly birthday and anniversary celebrations
About us:
At Total Expert, we strive for excellence, innovation and customer success in everything we do. We are determined to reimagine the way people and technology work together so that we can allow our customers to build more meaningful, human connections with their customers.
Simply put, we believe that we are all a part of building something awesome and are committed to creating a world-class team and culture to do it.
In 2019, Total Expert made the Inc. 500 list of fastest-growing companies in the country at spot #105 and was the second fastest-growing Minneapolis-based company on the list. In addition to being awarded a Top Workplace by the Minneapolis-St. Paul Star Tribune (2018, 2019), we have also been recognized as a HousingWire Tech100 and Minne Inno 50 on Fire award winner in 2019.",3
"Overview:

Wells Fargo technology teams drive innovation to create a more powerful and fulfilling financial experience for our customers and team members. You will join more than 24,000 team members supporting 95 billion transactions annually in 10 countries. Our career opportunities span the technology spectrum: advanced analytics, big data, information security, application development, cloud enablement, project management and more.

SUCCESS PROFILE

Check out the top traits we're looking for and see if you have the right mix. Additional related traits listed below.

Analytical
Detail-oriented
Insightful
Inventive
Problem Solver
Curious
Benefits

Wells Fargo wants to help you get more out of life and take care of things outside the office to make life a little easier. We provide:

Medical, Dental and Vision
Employer Matching 401(k)
Tuition Reimbursment
Maternity and Paternity Leave
Paid Time Off
Responsibilties
Job Description

Important Note: During the application process, ensure your contact information (email and phone number) is up to date and upload your current resume when submitting your application for consideration. To participate in some selection activities you will need to respond to an invitation. The invitation can be sent by both email and text message. In order to receive text message invitations, your profile must include a mobile phone number designated as “Personal Cell” or “Cellular” in the contact information of your application.
At Wells Fargo, we have one goal: to satisfy our customers’ financial needs and help them achieve their dreams. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience.
Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.
This role is a part of DMI’s Enterprise Analytics Team – the central analytics group tasked with solving high-impact business challenges and standing up cutting-edge analytical capabilities to be shared across Wells Fargo’s analytic community.
We are looking for a high performer to join our team and help us solve challenging and interesting business problems through rigorous data analysis and predictive modeling. In this foundational role, you will support Customer Genome program. This initiative is focused on creating analytically derived insights to inform development of personalized customer experience and marketing programs. As part of the core Customer Genome team, you will collaborate with other data scientists to generate innovative ideas, define analytical needs, create hypothesis, conduct data discovery, data wrangling, and exploratory data analysis, evaluate data quality, and prepare datasets for building statistical models and machine learning algorithms. You will also help training, testing and deploying machine learning models.
Key Responsibilities Include:
Extract, transform and load data from multiple databases, validate integrity and prepare modeling datasets.
Understand business context of the data and perform in-depth exploratory data analysis (EDA) and present data discovery results and findings with business partners and others
Provide recommendations to data scientists to support complex predictive modeling projects.
Respond to ad-hoc requests from business partners to conduct data analysis to identify/quantify opportunities or address specific business questions.
Utilize emerging analytical and programming techniques to explore internal and external unstructured and semi-structured data; recommend how these additional data sources can be used to enhance existing data and provide additional insight.
Work with complex databases, conduct in-depth research to gain domain knowledge about the data and identify data issues, and propose solutions to improve data integrity; perform other database-related analyses and projects as requested.
Data Management and Insights (DMI) is transforming the way that Wells Fargo uses and manages data. Our work enables Wells Fargo to empower and inform our team members, deliver exceptional experiences for our customers, and meet the elevated expectations of our regulators. The team is responsible for designing the future data environment, defining data governance and oversight, and partnering with technology to operate the data infrastructure for the company. This team also provides next generation analytic insights to drive business strategies and help meet our commitment to satisfy our customers’ financial needs.

Required Qualifications

8+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 5+ years of experience in one or a combination of the following: reporting, analytics, or modeling
4+ years of SQL experience
4+ years of ETL (Extract, Transform, Load) Programming experience
5+ years of experience with data manipulation, cleansing, and transformation
4+ years of Hadoop experience
2+ years of Python experience
4+ years of Hadoop experience with Spark

Desired Qualifications

Extensive knowledge and understanding of research and analysis
Strong analytical skills with high attention to detail and accuracy
Excellent verbal, written, and interpersonal communication skills
Extensive knowledge and understanding of research and analysis
Excellent verbal, written, and interpersonal communication skills
Strong analytical skills with high attention to detail and accuracy
1 + years of machine learning experience

Other Desired Qualifications

Experience working with big data infrastructure and tools (e.g., Hadoop, Spark, Hive, H2O).
Strong programming skills using SQL, Python with ability to manipulate data for analytical purposes and conduct statistical data analysis.
Knowledge of statistical techniques (e.g., probability, multivariate data analysis, regression, PCA, time-series analysis) and experience using machine learning algorithms.
Exposure to deep learning model deployment will be plus
Exceptional analytical skills with high attention to detail and accuracy; strong acumen proactively diagnosing and resolving data issues to ensure accuracy and completeness.
Prior experience in a role requiring collaboration across multiple functions within an organization, ability to translate and summarize complex data into understandable, actionable information and recommendations.
Proven ability to drive each project to completion with minimal guidance while effectively managing multiple projects at a time, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment.




Disclaimer

All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act.

Relevant military experience is considered for veterans and transitioning service men and women.

Wells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.

ENT FINANCE",3
"DISQO is a next generation consumer insights platform. We provide the highest quality consumer data to the world's largest market research agencies, analytics companies, and brands. We operate one of the world's largest true consumer insights panels. This data helps our clients understand user behavior, build better experiences, and make better decisions. We utilize cutting-edge technology and innovative, out-of-the-box strategies to collect and analyze insights which help shape the products and services of tomorrow.

This is a great opportunity to join a fun, exciting & highly motivated team and upgrade your skills while creating real impact. We use a modern tech stack and cloud infrastructure. We are not only looking for work experience, but rather the willingness to step up to challenges and the ability to learn quickly.

We believe the best software is written and managed by small teams that know how to make the impossible possible. We use agile software development techniques and modern tools to focus our efforts on solving our business goals. We use OKRs to track everything we do. We deliver early and often. We obsess over our code, architecture and infrastructure and we believe that these practices lead to higher quality products.

Check out the DISQO Developer Blog for the latest from our DISQOTECH team.

What you will do:

Leverage your software development and data engineering skills to impact our business by taking ownership of key projects requiring coding and data pipelines
Collaborate with product managers, software engineers and data engineers to design, implement, and deliver successful data solutions
Define technical requirements and implementation details for data solutions
Design, build and optimize performant databases, data models, integrations and ETL pipelines in RDBMS and NoSQL environments
Maintain detailed documentation of your work and changes to support data quality and governance
Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to the customers
Be an active participant and advocate of agile/scrum practices to ensure health and process improvements for your team

What you bring to the table:


5+ years of experience designing and delivering large scale, 24/7, mission-critical data pipelines and features using modern big data architectures
3+ years of Scala
3+ years of Spark
2+ years of experience with AWS data ecosystem (Redshift, EMR, Glue, Athena, ...)
Deep knowledge in various ETL/ELT tools and concepts, data modeling, SQL, query performance optimization
Experience with building stream processing applications using Kinesis or Kafka
Experience with workflow management tools (Airflow, Oozie, Azkaban, Luigi, etc.)
Comfortable working in Linux environment
Ability to thrive in an agile, entrepreneurial start-up environment

Benefits & Perks:

100% covered Medical/Dental/Vision for employee
Equity
Unlimited Vacation
Flexible work hours
Catered lunches 3x a week
Stocked pantry
Happy Hours
Onsite Fitness Program
Discounted Gym Membership
Quarterly Offsites
401K
Life Insurance
FSA
Paid Maternity/Paternity leave
Employee Assistance Program
Travel Assistance Program

DISQO is an equal opportunity employer
Recruiting firms that submit resumes to DISQO without first entering into a written contract will not be entitled to any compensation on candidates referred by that firm.

DISQO Developer",3
"Overview:
SOS International LLC (SOSi) is seeking a Data Scientist to join our team in Vienna, VA. The Data Scientist will be a SME in architecting complex analytic solutions from a multitude of multi-national “big data” sets on a variety of highly sensitive and complex data sets. Driving a comprehensive data collection and exploitation strategy that will address worldwide trinational issues. This person will be using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. Working with a wide range of stakeholders and functional teams. The Candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholder to imporve business outcomes.

Candidates must be technically adept to provide technical, strategic guidance to senior level database administrators and application developers in the creation and implementation of new databases, as well as the maintenance of major existing databases supporting evolving applications. Duties include leading and consulting to all levels of the organization on the design, development and implementation of logical database structures and classification schema; and developing policies and procedures to build, maintain and leverage the data model; provide technical, strategic guidance on the development of metadata tags, Document Type Definitions, and schemas using appropriate technologies for representation such as HTML and XML. Ensure that metadata and data standards and definitions will support both local business processes and system implementations thereof, and corporate requirements for sharing data.
Responsibilities:
Develop comprehensive Enterprise Data Collection and Exploitation Strategies that align with client transitional mission sets
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Develop and recommend data management policies, standards, practices and security measures to ensure effective and consistent data management operations.
Develop methods of ensuring that the data incompatibilities among systems are systematically eliminated, diagnose, isolate and expediently resolve complex problems pertaining to data infrastructure.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Qualifications:

Possess an active in scope Secret Clearance
10+ years professional experience in solutioning complex data solutions
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience working with and creating data architectures.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
We’re looking for someone with 10 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:
Coding knowledge and experience with several languages: C, C++, Java,
JavaScript, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.
Display thorough knowledge of missions and needs, and considerable knowledge of Intelligence Community missions, needs, and information sharing requirements.
Possess knowledge of backup or archival software — Acronis Recovery Expert; Backup and archival software; Systems and data disaster recovery software; VERITAS NetBackup
Possess knowledge of database management system software — Database management software; Microsoft SQL Server; Quest Central; Sybase Replication Server.
Possess knowledge of development environment software — C; Microsoft Visual Basic; Prolog; Restructured extended executor REXX.
Possess knowledge of data modeling software; IBM Rational Data Architect; Visual Paradigm DB Visual ARCHITECT.
Possess knowledge of object or component oriented development software — Microsoft Visual C# .NET; Practical extraction and reporting language Perl; Sun Microsystems Java; Sybase PowerBuilder.
Preferred Qualifications:
Fluency in a foreign Language
Working Conditions:
Normal office working conditions with possible requirement to lift and/or move objects or packages of up to 25 lbs
Periods of non-traditional working hours including consecutive nights or weekends when necessary",3
"JOB SUMMARY
Responsible for maintaining scalable and reliable data pipelines that support data operations for Reporting, Analytics, Applications, and Data Science by gathering and processing raw data at scale. Delivers solutions by developing, testing, and supporting cloud-based streaming applications. Develops data set processes for data modeling, mining, and consumption.

MAJOR DUTIES AND RESPONSIBILITIES
Actively and consistently supports all efforts to simplify and enhance the customer experience.

Create and maintain scalable, reliable, consistent and repeatable pipelines that support data operations for Reporting, Analytics, Applications, and Data Science.

Gather and process real-time data at scale (including writing APIs, stream processing jobs, and aggregation jobs).

Expertly use cloud-based tools to ingest and process data.

Profile data to measure quality, integrity, accuracy, and completeness.

Manage life cycle of multiple data sources.

Increase speed to delivery by implementing workload/workflow automation solutions.

Interact with various stakeholders to understand their business needs, communicate project status and develop relationships to ensure satisfaction

Perform other duties as assigned.

REQUIRED QUALIFICATIONS
Skills/Abilities and Knowledge
Ability to read, write, speak and understand English
Ability to use a wide variety of open source technologies and cloud services
Strong coding experience using Scala or Java
Strong background in Linux/CentOS installation and administration
Strong knowledge in data storage that demonstrates knowledge of when to use a file system, relational database, or NoSQL variant
Strong experience with Spark or Hadoop/Hive
Experience receiving, converting, and cleansing big data
Ability to identify and resolve end-to-end performance, network, server, and platform issues
Attention to detail with the ability to effectively prioritize and execute multiple tasks
In-depth knowledge of Agile development methodologies

Education
Bachelor's degree in an engineering discipline or computer science

Related Work Experience
3-5 years of designing and building Scala or Java applications
2+ years of designing and building cloud native applications
2+ years of Linux/Unix/CentOS system admin
1+ year(s) of designing and building Kafka or Kinesis applications

WORKING CONDITIONS
Office environment",3
"The Data Analyst Associate performs tasks related to the design, implementation, support/maintenance, and enhancement of NU's enterprise, vendor and in-house developed applications. Documents functional requirements, analyzes requirements in the context of software and processes, develops and executes test plans, assists with and documents business process improvement efforts, and works with production issues. Completes content, process, and procedures for technical and functional system work that is low in complexity. Receives direction and oversight from senior staff.
Specific Responsibilities:
Strategic Planning
Participates with senior analysts, end users and peers to ensure that user requirements are gathered, analyzed, all gaps are documented, and all deliverables completed (adhering to approved methodology and documentation standards).
Participates with functional users and technical staff to determine best approaches, ensuring that approved solutions are implemented in a timely and correct fashion.
Administration
Contributes to the creation of accurate documentation of process, procedure, and system/application configuration.
Provides input into the creation and maintenance of test scripts, implementation project plans, roll out communications and training materials.
Identifies simple use cases.
Development
Provides input into test scripts and performs detailed testing for simple use cases to ensure that the implemented software functions correctly.
Participates in iterative feedback processes among users, developers, and analysts to ensure software functionality aligns with requirements.
Performance
Enters basic software configurations to meet user needs.
Collaborates with technical, reporting and application resources to analyze and resolve basic production issues in a timely manner.
Performs other duties as assigned.
Minimum Qualifications:
Successful completion of a full 4-year course of study in an accredited college or university leading to a bachelor's or higher degree in a major such as computer science, information technology, or related; OR appropriate combination of education and experience.
Preferred Competencies: (Skills, knowledge, and abilities)
Experience configuring or administering a Student Information System software package such as Salesforce, PowerSchool, eSIS, Infinite Campus, Genius SIS, or similar product.
Experience configuring or administering a Learning Management System (LMS) such as Schoology, Moodle, Canvas, Blackboard Learn or similar product.
Experience creating training or documentation materials and providing technical assistance to personnel in a K-12 or higher education setting.
Ability to create and quality check SQL database queries.
Advanced Excel skills.
Experience using or willingness to learn a data visualization software package such as Tableau.
Experience using or willingness to learn a statistical analysis software package such as SAS, STATA, or SPSS.",0
"Simpluris is a national class action settlement administrator established in 2007 with offices in Florida and California. We provide a suite of technology-based services to develop, execute and administer class action lawsuits from discovery through distribution. With a strong focus on customer service and utilizing proprietary systems and innovative solutions, Simpluris has built a first-rate reputation for handling cases. Our core values and our commitment to excellence drive our Mission in providing premium settlement administration services. We are a purpose driven company made up of an ever expanding team of purpose driven people.
The opportunity looks like this...
Simpluris seeks to grow its Data Analyst team in our Winter Park, Florida office. We are primarily looking for an individual with a naturally analytical and curious mind who can see past the surface and understand the depth and complexities of the various issues a particular problem possesses and whom can identify clear paths to solutions. They must be able to view a problem from multiple angles and aspects to understand the client's needs. Most of our data projects are presented in a word problem type format which must be read and the project requirements extrapolated out from. This position requires working with our project management team in receiving various types and sources of data, interpreting and developing data project requirements, and utilizing tools such as Python, Excel, and SQL to cleanse, transform, and perform calculations against data as necessary for internal and external systems. The ideal candidate will have advanced Microsoft Excel skills, some experience utilizing Python or SQL, flourishes in a team dynamic, and possesses a passion for efficient and real world data applications. This opportunity is best suited for the self-starter who enjoys solving problems and wishes to be part of a fast-paced environment where they might challenge themselves and expand their knowledge and experience.
Requirements
Here is what we need from you...
Proficiency in data manipulation using MS Excel (Pivot Tables, VLOOKUP, etc.), SQL (SELECT/JOIN), and/or Python (Pandas, NumPy)
Ability to succinctly explain and thoroughly document steps of data analysis
Ability to follow instructions / SOP’s and develop new SOP’s
Ability to self-manage and work independently as needed
Ability to communicate data issues effectively to non-technical users
Here is what you will be doing...
Perform data cleansing/de-duplication/merging/calculation/analysis
Deal with various forms and sources of data utilizing tools including Microsoft Excel, SQL, R & Python
Interpret and develop project data and calculation requirements
Identifying and developing improved processes and workflows
Prioritize, organize, and audit work effectively against deadlines
Interface with internal/external staff & clients (technical & non-technical) directly resolving issues with data
Skillsets we’re looking for...
Solid critical thinking, analytical, and problem solving abilities
Comfort with basic algebra, logic, and statistics
Strong interpersonal communication skills (both oral and written)
High proficiency (i.e. Power User) in Microsoft Excel with knowledge of VLOOKUP, pivot tables, and other advanced functions
Some experience with a programming language (e.g. SQL, C#, JavaScript) a plus
Python or R experience preferred
Ability to learn new tools and business processes quickly
Prior experience performing ETL (extract, transform, and load) functions a plus
Prior experience with reporting (e.g., SSRS) or dashboarding (e.g., PowerBI) a plus
Education with majors related to IT/MIS, accounting, math, or similar programs
Benefits
If you think you have what it takes, come join our growing team of purpose driven people! This is a full time, permanent position and compensation is dependent upon experience. We offer benefits such as medical, dental, vision, life insurance and 401k plus bonus opportunities. Please submit salary requirements along with resume.
This is who we are…
Find out more about Simpluris, our company, our people, and our culture here:
YouTube Simpluris Culture Video (https://youtu.be/8kQzzp-D8bs)
https://www.linkedin.com/company/simpluris-inc
https://www.facebook.com/simpluris/
At Simpluris, we live by a code and our code is defined through our core values. We are looking for those who can commit to and live by these values as those are the type of individuals who will be successful and thrive here. However, if you feel you don’t resonate with these values, or if you’re not able to engage at this level, we’re probably not a good fit for one another. We expect from ourselves and those who choose to join us to be accountable for themselves and perform at or above the same level we do.
We realize not everyone is ready for this level of engagement and appreciate the recognition by those who are honest to see this is the not right fit or place for them. But for those who can commit, we believe you would make an ideal candidate to join our team based on our following core values:
Simply Elevate – Elevate yourself & others. We are stronger together.
Be Responsive – Move & execute.
Deliver – Do what you say you’re going to do. Say what you mean & mean what you say.
Exude Passion – Find the greater purpose, fully commit and participate with passion.
Work Without Boundaries – See it, own it, solve it, do it. Success is everyone’s responsibility.
Solutions Driven – Go beyond the surface, seek to continually improve & refine.",0
"Strength Through Diversity
Ground breaking science. Advancing medicine. Healing made personal.

The Data Analyst II oversees activities related to data integrity, security and enhancement of the value of data. The Data Analyst II may direct the movement of data across multiple systems; oversee its validation and organization and make sure that data is available to appropriate people and systems within an organization. The Data Analyst II will also develop and execute reports that will be important assets of the practice as they continue to develop and evaluate a new model of care.

Roles & Responsibilities:
Work with the clinical and administrative staff of the practice to define data reporting needs
Develop analytic reports that are easily understandable by clinical and administrative staff
Use modeling techniques and tools in analyzing and specifying data structure
Implement best practices in data management to ensure the integrity of the data, the quality of data processes and deliver analyzable or analyzed data to a variety of internal and external clients of the affiliated practice
Maintain data integrity and completes data analysis as necessary
Complete data capture, data extraction and analysis
Develop, maintain or implement procedures for data entry, data cleaning, documentation and other administrative tasks
Document, implement, maintain or recommend operating methods to improve processing, distribution, data flow, collection, database editing procedures
May define parameters for file or space utilization
Work closely with IT management and staff
Access data in the Data Warehouse, as required
Assist clinical and administrative staff with queries, statistical analyses, reports and technical difficulties related to data retrieval
Design and write custom applications needed to ensure the database meets requirements for the entry, management and reporting of data
Identify and recommend solutions to data management issues
Maintain knowledge of the current regulations and technologies related to data management
Write and prepare manuscripts and other materials for internal and external audiences
Perform other related duties
Help to build and perpetuate a practice environment and culture of collaboration, respect, learning, flexibility and fun among all team members
Requirements:
Bachelor’s degree or equivalent education/work experience. Master’s degree in relevant field of study preferred
3 years of analytics experience including report development and database application/management experience, preferably in a large medical center or healthcare environment
Advanced knowledge of database applications / management, SQL and /or SAS. Knowledge of computer programming preferred
Excellent conceptualization, design and analytical skills
Excellent written and oral communication skills
Exceptional attention to detail and accuracy
Strength Through Diversity

The Mount Sinai Health System believes that diversity is a driver for excellence. We share a common devotion to delivering exceptional patient care. Yet we’re as diverse as the city we call home- culturally, ethically, in outlook and lifestyle. When you join us, you become a part of Mount Sinai’s unrivaled record of achievement, education and advancement as we revolutionize medicine together.

We work hard to acquire and retain the best people, and to create a welcoming, nurturing work environment where you can develop professionally. We share the belief that all employees, regardless of job title or expertise, can make an impact on quality patient care.

Explore more about this opportunity and how you can help us write a new chapter in our story!

Who We Are

Over 38,000 employees strong, the mission of the Mount Sinai Health System is to provide compassionate patient care with seamless coordination and to advance medicine through unrivaled education, research, and outreach in the many diverse communities we serve.

Formed in September 2013, The Mount Sinai Health System combines the excellence of the Icahn School of Medicine at Mount Sinai with seven premier hospital campuses, including Mount Sinai Beth Israel, Mount Sinai Beth Israel Brooklyn, The Mount Sinai Hospital, Mount Sinai Queens, Mount Sinai West (formerly Mount Sinai Roosevelt), Mount Sinai St. Luke’s, and New York Eye and Ear Infirmary of Mount Sinai.

The Mount Sinai Health System is an equal opportunity employer. We promote recognition and respect for individual and cultural differences, and we work to make our employees feel valued and appreciated, whatever their race, gender, background, or sexual orientation.

EOE Minorities/Women/Disabled/Veterans",0
"Gatestone & Co. is looking for an efficient, detail-oriented Data Analyst. The Data Analyst will be responsible for facilitating the issuance of letters and digital communications to consumers, in accordance to regulatory and client expectations.
Our ideal candidate is self-motivated and produces high-quality work. They are able to prioritize tasks appropriately and effectively, and handle multiple tasks at once, while maintaining strong follow-up skills to ensure all responsibilities are handled.
In this role you will:
Complete service requests as it relates to the creation of new letters and digital communications
Perform daily tasks relating to quality control and data validation
Demonstrate accuracy and thoroughness; look for ways to improve and promote quality; apply feedback to improve performance; monitor own work to ensure quality
Assist the Compliance Manager in the development of an effective record keeping system, including letter approvals, letter log, and inventory and regulatory requirements
Import/export data from text format into Excel and vice versa, while maintaining field-level integrity and data accuracy
Work closely with IT and other departments in regards to letter status, communications to consumers, etc.
Other duties as assigned

Who We Are
Founded in 1926, Gatestone is an industry leader providing exceptional outsourced Customer Contact Centre and Business Process Outsourcing (BPO) solutions to the world’s most respected organizations. Our clients are some of the world’s most respected organizations including Fortune 500 companies.
Started by Nicholas Wilson from humble beginnings, Gatestone has grown into a major global outsource provider with 10 fully-integrated sites located across North America, Latin American, Central America and Asia offering skill sets across multiple experience levels and languages. Still under original ownership, the company is supported by a long-tenured management team who provide unparalleled strategic leadership at all levels throughout the organization.

Benefits of Working at Gatestone
At Gatestone, we understand that our corporate success starts by attracting the right people, developing and mentoring those that show potential and taking steps to retain and promote our top performers.
We believe in our employees and invest in providing the best growth opportunities. Promotions at Gatestone are based on merit, past performance, and leadership potential. We recognize our top employees and help them succeed. We also have a full time Employee Engagement Specialist who ensures we have fun while working hard!
When you join Gatestone, you do more than join a company. You become part of a team of talented and self- driven individuals dedicated to bring success to the Company and their lives.
Be a part of an Awarding Winning Company.
Check us out in Instagram to see how much fun the Gatestone experience really is!
https://www.instagram.com/gatestonebpo
Skills Required:
An analytical thinker, able to synthesize complex or diverse information, collect and research data, use intuition and experience to complement data; able to manage specialized work efficiently with confidence and competence
A problem solver who identifies and resolves problems in a timely manner; gathers and analyzes information skillfully, uses reason even when dealing with emotional topics
Ability to read, analyze, and interpret corporate, compliance, and legal documentation, as needed
Detail oriented, well organized and has proven ability to work within stringent timeframes
Excellent verbal, written, listening, and interpersonal skills
Efficient with troubleshooting
Familiarity with ticketing systems

Qualifications:
2+ years in an administrative role
Proficient with Microsoft Office suite
Knowledge of AS400 is required
Ability to pass a background check and drug screen
High school diploma or GED is required",0
"About the Department of Pathology:
Comprised of extraordinary faculty and staff, our mission is to improve the diagnosis, treatment and basic understanding of human disease. We accomplish this through our clinical services, research, and training the future leaders in pathology and related fields. A major focus of clinical research in the Department continues to be the correlation of patient outcome and treatment response with the surgical pathologic diagnosis of human cancers. Everything we do is to provide the highest quality of pathology diagnostic services to the patients for whom we passionately care.

For more information about the department visit http://pathology.stanford.edu/


About the Position:
We are seeking a Research Data Analyst 1 to join the group of Dr. Mike Angelo at the Stanford Blood Center in the Department of Pathology. This Data Analyst will aid in the development of algorithms and software for analysis of highly-multiplexed imaging data generated by a next-generation IHC platform (Multiplexed ion beam imaging) housed in the Angelo lab. A strong background in analyzing biological imaging data is desired. The Data Analyst will play a key role in designing, building and maintaining the analytical pipelines used for routine image analysis in the lab. Additionally, the Data Analyst will develop new methods for image segmentation, object identification and phenotyping. In addition to these cross-project responsibilities, the Data Analyst will also be involved in individual project, assisting M.D.s and Biology Ph.D.s in their data analysis tasks. Must be a good team player.
Duties include:
Collect, manage and clean datasets.
Employ new and existing tools to interpret, analyze, and visualize multivariate relationships in data.
Create databases and reports, develop algorithms and statistical models, and perform statistical analyses appropriate to data and reporting requirements.
Use system reports and analyses to identify potentially problematic data, make corrections, and determine root cause for data problems from input errors or inadequate field edits, and suggest possible solutions.
Develop reports, charts, graphs and tables for use by investigators and for publication and presentation.
Analyze data processes in documentation.
Collaborate with faculty and research staff on data collection and analysis methods.
Provide documentation based on audit and reporting criteria to investigators and research staff.
Communicate with government officials, grant agencies and industry representatives.

Desired Qualifications:
Bachelor’s degree in Mathematics, Statistics, Computer Science or related field.
Research experience in computational biology desired; specifically in analysis of high-throughput, multiplexed data. Experience in designing data analysis pipelines is an advantage.
Experience in industry as software engineer is desired; specifically is generating graphical user interfaces.
Knowledge and experience in machine learning is highly desired; specifically application of deep learning to computer vision and image analysis.
Intimate knowledge with at least one of the following programming languages: Python/R/Perl/Matlab/Java/C/C++
The candidate should be able to work independently, be highly motivated, well organized, adaptable and work well within a highly interdisciplinary and international team. Good communication and interpersonal skills as well as fluent English are essential, as well as proficient computer skills (Mac and PC).
Education & Experience:
Bachelor's degree or a combination of education and relevant experience. Experience in a quantitative discipline such as economics, finance, statistics or engineering.

Knowledge, Skills and Abilities:
Substantial experience with MS Office and analytical programs.
Strong writing and analytical skills.
Ability to prioritize workload.

Certification & Licenses:
None
Physical Requirements:
Sitting in place at computer for long periods of time with extensive keyboarding/dexterity.
Occasionally use a telephone.
Rarely writing by hand.

Working Conditions:
Some work may be performed in a laboratory or field setting.",0
"Junior Data Analyst
A content technology platform, Nativo helps advertisers create meaningful brand connections with consumers and empowers publishers with breakthrough monetization solutions. We're preparing the world for the age of content, where digital advertising is becoming a seamless, authentic, and helpful consumer experience.
We invite you to join us for an exciting and rewarding experience as a Junior Data Analyst. This role will assist the Campaign Operations team by providing analytic support through measuring the effectiveness of active and completed native advertising campaigns. This individual will collaborate with other internal departments to advance the capabilities provided by the Analytics team.
What you'll do:
Perform data cleansing/de-duplication/merging/calculation/analysis
Prepare spreadsheets and PowerPoint presentations for clients
Proactively identify potential gaps in data and take the initiative to resolve issues
Provide assistance in other areas of the department/company as needed
What you need:
1-year minimum work experience in campaign analytics
Proficient with Excel (Vlookups, pivot tables, chart visualizations, etc.)
Basic understanding of concepts in online campaign analytics or brand study measurement
Comfortable working with PowerPoint
Exceptional written and verbal communication skills and the ability to present analysis to various levels of management and staff.
Intellectual curiosity to enjoy problem-solving and ask the right questions to arrive at an insight
Excellent teamwork skills
Ability to work well without constant direction
Must enjoy working in a fast-paced entrepreneurial startup environment
BA/BS degree in Business, Marketing, or related field
What We Offer:
At Nativo, you make an immediate impact. Nativo is made up of smart, talented and driven people looking for other potential team members with the same attitude of innovation and excellence. We offer incredible opportunities to learn and work on projects that transform digital advertising. We offer a competitive compensation and benefits package that includes stock options, health coverage, employer-matched 401k, cutting edge work, and the opportunity to join a rapidly growing startup with a proven product.
About Nativo
Nativo empowers brands and publishers with the world's most advanced platform for content.
For brands, Nativo enables storytelling at scale with the largest native reach and reveals insights that unlock return-on-content. For publishers, Nativo enriches monetization with the most comprehensive platform for next-generation ad formats and breakthrough technology for accelerated webpages. Nativo's mission is to equip advertising for the age of content, improving the web experience and creating meaningful connections for today's digital consumer.
From the hands and minds of an amazing team, Nativo has engineered a platform that has been recognized as the best available in the market. Nativo is respected, well-funded, and is recognized as one of the top tech companies to work for. Nativo is well-positioned to play a vital role in forging the path of media and advertising in the coming years. The opportunity to join a team that is making a huge impact is now.
For information on what personal information Nativo collects and how we use it, please see our CCPA privacy notice: https://nativo1.box.com/s/a0j9eonmrveq3ot6mgldvy3jm4f0msu4

Emy7kIdKKf",0
"Req. ID: 180202
Micron Technology’s vision is to transform how the world uses information to enrich life and our commitment to people, innovation, tenacity, collaboration, and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions. This means conducting business with integrity, accountability, and professionalism while supporting our global community.
We are seeking motivated individual to join our machine learning and deep learning team. Your role is to maintain and use state-of-the-art deep learning algorithms and tools. The team products are high-performance computer vision algorithms, demonstrations, hardware, compilers.
Responsibilities include, but not limited to:
Build and maintain:
Deep learning frameworks, software and models to train neural networks models
Learning scripts and custom learning criterion, optimization modules
Dataset of images and videos
Dataset scripts
Web-optimized scripts for server-side processing
Validation scripts, measure dataset and model performance, and run them on Linux computer clusters
Build code for applied computer vision: saliency, tracking, detection, recognition, localization
Read literature, summarize results, and present results and innovations to the team
Reproduce and validate state-of-art models from papers and publications
Interact with customers, accept and review software and product requirements, satisfy requirements.
Minimum Qualifications:
MS/PhD in Computer Science, Computer Engineering, Electrical Engineering, Physics or related experience
Minimum 5+ years experience on computer vision, machine-learning and deep learning algorithms, including Deep, Convolutional, Recurrent Neural Networks
Experience writing and maintaining professional software using: C, C++, Python, PyTorch, TensorFlow, Caffe or similar deep learning framework
Leader in machine learning competitions, and international datasets
Deep knowledge of machine / deep learning literature, especially recent years after 2012
Open source contributions
State-of-art knowledge of at least one of these computer vision techniques: face-identification, tracking, localization, detection, recognition, saliency, video-processing, image embeddings, similar images, video summarization, language models for image and video description, openCV, etc.
Excellent presentation, written and verbal skills, proven by international level conference participation, acclaimed web blogging
Preferred Qualifications:
Award winner during PhD
Multiple international journal articles or conference presentations
Highly ambitious with forward-thinking and entrepreneurial aspirations
Background knowledge on parallel/heterogeneous programming (CUDA / OpenCL)
Background in Linux administration
Able to set up servers and clouds of servers
Experience in at least one area: text translation, speech recognition, text analysis, sentiment analysis
Experience with recurrent network or similar: RNN, LSTM, neural attention and associative memories
Experience in multimedia Linux software, libav, image and video compression / decompression, formats, processing with ffmpeg, libav and similar
Experience in embedded ARM setup, configuration and use: Raspberry Pi or similar
Graphic design, web design, CAD design
Artistic insights and abilities
About Us
As the leader in innovative memory solutions, Micron is helping the world make sense of data by delivering technology that is transforming how the world uses information. Through our global brands — Micron, Crucial and Ballistix — we offer the industry’s broadest portfolio. We are the only company manufacturing today’s major memory and storage technologies: DRAM, NAND, NOR and 3D XPoint™ memory. Our solutions are purpose built to leverage the value of data to unlock financial insights, accelerate scientific breakthroughs and enhance communication around the world.
Micron Benefits
Employee Rewards Program, Healthcare, Paid time off (Combined Sick and Vacation Time), Retirement savings plans, Paid maternity/paternity leave, Employee Assistance Program, Professional development training, Workplace wellness programs, Micron Health Clinic (Boise only), Fitness Center/Activity rooms (Boise/San Jose only), Tuition Reimbursement, Micron Corporate Discounts, Casual Dress attire.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.
For US Sites Only: To request assistance with the application process and/or for reasonable accommodations, please contact Micron’s Human Resources Department at 1-800-336-8918 or 208-368-4748 and/or by completing our General Contact Form
Keywords: Seattle || Washington (US-WA) || United States (US) || DEG (DRAM Engineering Group) || Experienced || Regular || Engineering || #LI-BG1 || Tier 4 ||",2
"Data Analyst - Equinox Media
Overview

OUR STORY:
We are a company with integrated luxury and lifestyle offerings centered on Movement, Nutrition and Regeneration. In addition to Equinox, our other brands, Blink, Pure Yoga, SoulCycle, Furthermore, Precision Run and Equinox Hotels are all recognized for inspiring and motivating members and employees to maximize life. Within our portfolio of brands, we have more than 200 locations within every major city across the United States in addition to London, Toronto, & Vancouver.
Job Description

It is an exciting yet critical time for our teams at Equinox Media and we're looking for a Data Analyst to join our Data team to help us invent new ways of connecting people to the communities and fitness that they love. If you're someone who is passionate about developing strategies based on insights from real people and data, and can turn those insights into opportunities for the business and product teams to grow, then this is the team for you. There will also be significant exposure to modern data processing and analytic tools as your work spans across the broader technology groups as well. Our team embraces a true entrepreneurial spirit; operating with a sense of pride, perseverance and care for one another. We strive to continually deliver the best results and focus on how every action taken helps push our mission forward.
What you'll do:
Providing data reporting functions to the business and technical community using SQL
querying
Working with business and technology partners to build insightful analytical solutions
Troubleshooting data discrepancies along with resolving and clarifying them
Identifying areas where operational efficiency can be improved through enhanced
automation along with implementing those enhancements
Help engineering team with profiling and onboarding new datasets.
Develop automated data profiling and quality checks
Qualifications

Bachelor’s Degree Required. MIS / Computer Science / Engineering / Data Science
discipline
Expertise in SQL Server/ Redshift; SQL analytic capabilities (with 4+
Years hands on experience in SQL)
4+ Years working as a Data Analyst with a strong ability to analyze data and perform
root cause analysis
Ability to extract information from multiple databases using complex query statements
and advanced database tools
Organize, analyze and disseminate medium to large amount of information with great
attention to detail and accuracy
Knowledge of analytic tools like Tableau
Good exposure to Data Warehouse principles and basic understanding of data modeling
concepts and methodologies
Experience working with structured and semi-structured data (xml, json)
Experience working with ticketing and project management systems (Zendesk, Jira)
Strong documentation and communication skills
Creative, flexible, eager to learn, and able to work successfully in a multi-project,
deadline driven environment within Agile framework
Excellent written and verbal communication skills required
Any marketing tools (Adobe, Braze, CDP, ExactTarget) experience a plus
Additional Information

Equinox Media is an equal opportunity employer. We celebrate unique points of views & experiences across age, gender identity, race, sexual orientation, physical or mental ability & ethnicity in building the future of our digital business. We aren’t just a company; we’re a community vested in each other’s success. We value humility and a team approach at every level of the company. We want to inspire a workplace where individuals embrace their differences and similarities, where we are building products and experiences that inspire and improve people's lives.
See what we're up to: https://www.fastcompany.com/90386259/soulcycle-at-home-equinox-announces-streaming-fitness-platform-equipment",0
"Requisition ID: 103442
Job Level: Mid Level
Department: Business Management
Market: Corporate Home Office
Employment Type: Full Time

District Overview
Kiewit Data Services’ (KDS) mission is to make Kiewit the premier data-driven organization in our industry. To accomplish this, our projects and districts need to have the right data, of the right quality, with the right level of analysis, available to them at the right time. KDS is a cross functional organization with employees that have expertise in data, technology, support and operations backgrounds. Our core functions are data Quality, Governance, Enablement, Analytics and Data Science.

Location
This position will be based out of Omaha, NE.

Responsibilities
Perform financial forecasting, reporting, and operational metrics trackingAnalyze financial data and create financial models for decision supportReport on financial performance and prepare for regular leadership reviewsAnalyze past results, perform variance analysis, identify trends, and make recommendations for improvementsWork closely with the accounting team to ensure accurate financial reportingEvaluate financial performance by comparing and analyzing actual results with plans and forecastsGuide cost analysis process by establishing and enforcing policies and proceduresProvide analysis of trends and forecasts and recommend actions for optimizationRecommend actions by analyzing and interpreting data and making comparative analyses; study proposed changes in methods and materialsIdentify and drive process improvements, including the creation of standard and ad-hoc reports, tools, and Excel dashboardsIncrease productivity by developing automated reporting/forecasting toolsPerform market research, data mining, business intelligence, and valuation compsMaintain a strong financial analysis foundation creating forecasts and modelsProficiency with Microsoft Excel is mentioned in virtually any financial analyst job description; familiarity with data query/data management tools is extremely helpful (Access, SQL, Business Objects)

Qualifications
0-3+ years of business finance or other relevant experienceHigh proficiency in financial modeling techniquesStrong fluency with Excel formulas and functionsBA, BS, or B.Com degree required (Bachelor’s Degree in Accounting/Finance/Economics)Strong analytical and data gathering skillsGood business acumenMBAs are preferredProven work experience in a quantitatively-heavy roleFMVA or similar designations preferredStrong quantitative and analytical competencySelf-starter with excellent interpersonal communication and problem-solving skillsAdvanced knowledge of ExcelAbility to streamline functions and passion to learn and growStrong interpersonal skills, including written and oral communication skillsComfort dealing with ambiguity and the ability to work independentlyExperience working with, and presenting to, senior executivesExcellent communication and presentation skills; be comfortable interacting with executive-level managementStrong financial modeling experience
Key Responsibilities
• Grow financial performance through analysis of financial results, forecasts, variances, and trends
Create recommendations to be presented to management and executivesDevelop financial models to support valuation, planning, and forecastingAid in the capital budgeting and expenditure planning processesReconcile existing transactions through cross-referencing of incoming and outgoing dataConduct comparables analysis and market research to support internal financial analysisMaintain up-to-date technical knowledge of financial instruments, market conditions, and trends

We are an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.",0
"We are looking for a Data Engineer to organize, manage, query, analyze terabytes of data from multiple different digital sources (mobile apps, websites, sensors). The ideal candidate has a passion for delving into data to help drive decision making in real-time for 180+ sports properties around the world.We are a 24/7/365 global sports entity, so a solid understanding and love of sports is highly recommended.We are looking for someone who...Thinks nothing is impossibleIs a tinkerer and implementor of big-data systemsHas a knack for data visualization to derive insightsIs equally comfortable with database systems and machine-learning algorithmsWhat you will be doing...Running analyses on terabytes of data that arise from digital assetsApplying machine-learning algorithms on data sets in order to cluster and segment themProviding insights from the data, to understand user behavior, predict user behavior, identify anomalies, and identify patternsBuilding, maintaining, and refining data dashboardsDriving new product development based on insights from the dataBe our MVP if you have...2 years+ of machine-learning experience with giant data-sets2 years+ of experience in data visualization techniques and best practices2 years+ of experience in working with Hadoop, Hive, Spark, and other big-data platforms2 years+ of experience with SQL, relational databases, NoSQL databases, including Postgres and Cassandra2 years+ of experience with Google Analytics, Firebase2 years+ of experience with AWS cloud services, such as EC2, EMR, RDS, Redshift2 years+ of experience in Java/C++/Python programmingExpert programmer and tinkerer, comfortable around operating systems, cloud computing, network protocolsWillingness to work in a high energy, fast-paced environmentStrong desire to learn and grow careerDegree in Computer Science/Engineering, with a heavy focus on machine-learning, data science, data engineering.Job Type: Full-timePay: $59,000.00 - $79,000.00 per yearBenefits:401(k)Dental InsuranceHealth InsurancePaid Time OffParental LeaveProfessional Development AssistanceRelocation AssistanceVision InsuranceSchedule:Monday to FridayWeekendsCOVID-19 considerations:To keep our employees as as safe as possible, we are working remotely and allowing new hires to begin their employment remotely, with the expectation that they will be able to relocate to Pittsburgh once it is safe to travel.Experience:machine-learning: 2 years (Required)SQL and relational database: 2 years (Required)Tableau: 2 years (Required)Hadoop/Hive: 2 years (Preferred)Java programming: 2 years (Required)Education:Bachelor's (Required)Location:Pittsburgh, PA 15206 (Required)Work authorization:United States (Required)Application Question:What is the largest data-set you have analyzed? And what techniques did you use to analyze it?Work Location:One locationCompany's website:www.yinzcam.comBenefit Conditions:Only full-time employees eligibleWork Remotely:Temporarily due to COVID-19",3
"Position Demographics
At the Regional Transportation District of Denver, CO (RTD) our mission is to meet our constituents' present and future public transit needs by offering safe, clean, reliable, courteous, accessible and cost-effective service throughout the District. We look for candidates to join our team in creating a legacy for current and future generations.
-
RTD is an equal employment opportunity employer. RTD is a Drug-Free Workplace.

The Immigration Reform and Control Act requires that verification of employment eligibility be documented for all new employees by the end of the third day of work.

The Regional Transportation District complies with the Americans with Disabilities Act (ADA), to provide reasonable accommodations for persons with disabilities.

RTD participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the Form I-9.

Description of Work
This position manages and supports activities related to developing, implementing and ensuring that reporting and document retention is in compliance with Federal Railroad Administrative Regulations, other regulatory requirements and internal Standard Operating Procedures.
Duties & Responsibilities
ESSENTIAL:

Develops and implements policies, business processes, strategies and procedures for document retention, and control to ensure compliance with organizational policies, relevant legislation, legal guidelines, Colorado Public Utilities Commission and Federal Railroad Administration Regulations and Reporting requirements.

Acts as the primary data analyst and ensures single document repository control for Configuration Management, Software Configuration Management, Safety and Security, Positive Train Control and Inspection Management as required for a FRA Regulated Railroad.

Serves as energy account manager and assists Senior Accountant to monitor, track, and audit traction power, signal, communication house energy usage, building power usage and billing and assists in forecasting departmental budget needs. Reports annually to the U.S. Department of Transportation National Transit Database (NTD).

Assists Safety and Security with NTD reporting for the Commuter Rail Network.

Analyzes information and evaluates results using logic and reasoning to identify the strengths and weaknesses of alternative solutions.

Assists in developing, planning and implementing FRA reporting structures, data reporting and retention as required, software and technical reporting improvements, training and resourcing staff concerning reporting management and organization. Ensures hours of service and other FRA retention reports are secured in the central repository.

Acts as liaison to Information Governance for internal document requests, CORA requests and provides support for Customer Care requests.

OTHER:

All job-related duties as assigned.
Qualifications
Bachelor's degree in Business Administration, Decision Science, Mathematics, Analytics, Engineering or a closely related field.

A minimum of four years of experience in records management or a document management environment.

A minimum of four years of experience with software such as Oracle, Aconex, RailDocs, Laserfiche or other reporting software,

A minimum of three years of experience in statistical analysis or data analysis with the ability to compile, code, categorize, calculate, tabulate, audit, and verify information and/or data and a minimum of two years of experience reporting and document retention in an FRA regulated railroad.

Knowledge of FTA/FRA/ADA/CPUC statutes, regulations, and laws associated with reporting and record management in an FRA regulated railroad preferred.

Ability to recognize information of a sensitive nature, and other issues requiring consultation with legal or escalation to subject matter experts.

Ability to work in a team environment and interpret the meaning of information for others by translating or explaining what the information means and how it is to be used.

Proficient with Microsoft Office Suite.

Ability to communicate effectively, orally and in writing.

Ability to use sound judgment.

Ability to manage time and workload effectively which includes planning, organizing, and prioritizing with attention to details.

OR:

An equivalent combination of education, experience, knowledge, skills, abilities.",0
"We are looking for a Senior Data Scientist to join our new Data Center and Networking AI Team to solve some of the hardest and most interesting technological challenges facing the industry today.
The Team
You will be joining a new team of world-class high-performing and low ego engineers and scientists that have an entrepreneurial and hacker spirit. The team will operate in a very self-driven, agile and fast-paced environment.
The team operates by self-organizing, around shared values, vision and objectives.
Keys to Hiring
You are the best candidate for this position if you are both mathematically inclined, self-motivated. You generate new ideas and initiatives to solve problems and identify trends and opportunities. You are comfortable working independently and figuring things out, and also enjoy working collaboratively in a small, fast-paced entrepreneurial environment. You enjoy being challenged and respectfully challenging others.
You write code almost every day and are comfortable working with your team to produce tools, pipelines, packages, modules, features, dashboards, or whatever is needed to move the team forward. You have a hacker’s spirit. You’re a quick study and technically flexible.
You have a strong ability to communicate about algorithms, complex data science methods, and statistical results to normal people in simple English using common ground, metaphors, and storytelling. You are intellectually curious, and enjoy looking at large data sets, to discover insights, and piece together stories. You like to develop a strong intuition to data by cleaning, organizing and labeling it. Other duties and responsibilities include, but are not limited to the following:
Build data pipeline to support data science needs
Build, test and deploy custom ML/AI models and algorithms on large datasets, and develop processes for monitoring and analyzing their performance on live mission critical environments
Drive innovation roadmaps to improve our machine learning models and experimentation techniques
Stay abreast with latest academic research to find best solutions for our use cases
Write or contribute to technical articles and white papers to showcase your work with visualizations to demonstrate ideas, challenges, algorithms, and results
Collaborate with academia and engineering/data science teams across companies and business units

Qualifications:
Ph.D. in Statistics, Computer Science, Machine Learning, Mathematics, Computational Psychology, Operational Research, Physics or relevant field
5+ years of most recent experience building models hands-on and track record of solving complex enterprise problems from scratch that went to production
Fluency in a programming language (Python, R, C, C++, Java)
Experience working with AI/ML technologies like TensorFlow, PyTorch, Keras, Caffe, scikit-learn, Spark MLlib and large-scale data sets and generating unique models and algorithms
Proficiency with analytical and database tools (e.g. Jupyter notebooks, Hive, Presto, SQL, No-SQL)
Strong background in classical machine learning and deep knowledge in a variety of techniques in feature selection, regression, classification, and clustering, and their real-world advantages and drawbacks
Domain knowledge of and hands-on experience building AI solutions for data centers, enterprise networks, WAN networks is a bonus",1
"WHAT WE'RE ABOUT

We're creating an airline people love. It begins with each Alaska Airlines employee, bringing unique strengths and energy to our work in the air and on the ground. Every day, we go beyond what's expected and reach for the remarkable, together.

YOUR ROLE

Role Summary

Become part of a dynamic environment that offers a hands-on internship experience. We are looking for talented and enthusiastic students to contribute toward key projects that support our business, community and cultural growth. Experience a work environment that thrives on innovation, collaboration and partnership.

Scope & Complexity

We want to talk to undergraduate students in their junior year who have accomplished outstanding academic results. The program is designed for a commitment of 40 hours per week for the duration of the 12-week program. When not working, we invite our interns to take advantage of unlimited complimentary space-available travel on Alaska Airlines or Horizon Air... Lunch in San Diego? Weekend in Portland? Maui? Phoenix... Done!

Key Duties

Build Azure Cloud based Azure Functions that read from Azure Service Bus and write data to a MongoDB based ODS and to an Azure Data Lake.

Build Python based integration tests.

Utilize established patterns and frameworks to develop deliverables.

Design JSON data structures suitable for key components in our enterprise ODS and data lake.

Work with a team of developers to define and produce deliverables.

Job-Specific Skills & Education

Required

Demonstrated ability to quickly learn a large number of new tools quickly.

Experience working with some or all of these: Azure Cloud Portal, Azure Functions, Azure Service Bus, JSON, MongoDB or MongoDB Atlas.

Experience coding with Python.

Experience working with Git source code control.

Internship positions are open to current undergraduate students in their junior year who are enrolled in a full time course of study graduating between December '20 and June '21.

High school diploma or equivalent is required.

Minimum age of 18.

Must be authorized to work in the U.S.

Preferred

Experience coding Azure Functions in Python using Visual Studio Code.

Experience setting up patterns and frameworks to enable building deliverables in a repeatable manner.

Demonstrated passion for producing top quality deliverables.

Job-Specific Leadership Expectations

Embody our values to own safety, do the right thing, be kind-hearted, deliver performance, and be remarkable.

START YOUR NEW JOURNEY NOW

Submit your application by 02/18/2020 11:59pm (Pacific Time). We'll be happy to see it.

EQUAL EMPLOYMENT OPPORTUNITY

Horizon Air and Alaska Airlines are equal opportunity employers. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age, protected veteran or disabled status, or genetic information.

Horizon Air and Alaska Airlines will consider for employment qualified applicants with arrest and conviction records in accordance with applicable Federal, State, and local laws.

Horizon Air and Alaska Airlines participate in E-Verify, a service of the Department of Homeland Security (DHS) and Social Security Administration (SSA), where required.

Job ID 36195

Location Seattle, WA

FLSA Status Nonexempt",3
"Ultimate Software understands the value of data. The Data Engineering team is seeking a Cloud Data Engineer to help us extract this value. The team is responsible for all stages of data lifecycle management which includes capture, maintenance and publication. You will be responsible for designing, developing, testing, deploying and supporting data management solutions. This includes BI development, data pipeline (ETL/ELT) development, API data integrations, data quality and process monitoring/alerting.

Here at Ultimate Software, we truly put our people first. We strongly believe in teamwork, and we encourage and trust our people to reach higher, learn more, and live up to their potential. Ultimate is ranked #1 on Fortune's Best Places to Work in Technology for 2020 and #2 on the 100 Best Companies to Work For list in 2020. Ultimate is also ranked #2 on Fortune’s 75 Best Workplaces for Women and #9 on its Best Workplaces for Diversity list. Learn more about US here: www.ultimatesoftware.com/careers

Primary/Essential Duties and Key Responsibilities:

Design, develop and support database entities, data pipelines and processes required
for data integration (ETL/ELT)
Implement processes that ensure data quality, code quality, and the confidentiality of
all data
Possess the ability to learn emerging technologies quickly and apply them effectively
Design, implement, lead and manage large-scale, enterprise-wide and complex data
projects
Define and comply with internal development coding standards, procedural guides,
and checklists for the support of the data platform.
Provide in-depth troubleshooting skills to assist in resolving errors and performance
issues, including tier 2 production support
Understand business requirements, contribute to technical requirements and deliver
on time within a SCRUM methodology.


Required Qualifications:

6+ years with relational databases and SQL
3+ years data warehouse and ELT/ETL experience
2+ years programming with Python (Pandas and other common libraries)
2+ years object oriented programming experience
2+ years API integration experience
1+ year experience performing data integrations or data warehousing in a cloud data
platform, preferably Google Cloud


Preferred Qualifications:

Experience with data warehousing using Big Query in Google Cloud.
Experience with GCP Services - Cloud Dataflow, Cloud Firestore, Cloud Composer and Stackdriver.
A broad range of knowledge across Big Data, Azure, Data Vault, Tableau and other emerging technologies.

Education/Certification/License:

Bachelor’s Degree in Information Systems or related discipline preferred.


Travel Requirements:

Limited upon request


This job description has been written to provide an accurate reflection of the current job and to include the general nature of work performed. It is not designed to contain a comprehensive detailed inventory of all duties, responsibilities, and qualifications required of the employees assigned to the job. Management reserves the right to revise the job or require that other or different tasks be performed when circumstances change.

Ultimate Software will reasonably accommodate employees with disabilities as defined by the Rehabilitation Act of 1973, the Americans with Disabilities Act (ADA) and other appropriate statutes. If you are an applicant and need a reasonable accommodation when applying for job opportunities within the Company or request a reasonable accommodation to utilize the Company’s online employment application, please contact accessibility@ultimatesoftware.com.",3
"Named as one of Fortunes’ 100 Fastest Growing Companies for 2019, EPAM is committed to providing our global team of 30,100+ EPAMers with inspiring careers from day one. EPAMers lead with passion and honesty and think creatively. Our people are the source of our success and we value collaboration, try to always understand our customers’ business, and strive for the highest standards of excellence. No matter where you are located, you’ll join a dedicated, diverse community that will help you discover your fullest potential.


Description

You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Senior Big Dara Engineer. Scroll down to learn more about the position’s responsibilities and requirements.


EPAM Big Data Practice is looking for the Cloudera Big Data Engineers. As the Cloudera Data Engineer, you will be responsible for design and implement the management, monitoring, security and privacy of data using the full stack of Cloudera Hadoop Ecosystem services to satisfy the business needs.

#LI-DNI
#LI-DNP
What You’ll Do
Implement non-relational data stores:
Implement a solution that uses Hive, HBase, Impala DB, HDFS
Implement data distribution and partitions
Implement a consistency model in Hive/HBase
Provision a non-relational data store in HDFS
Provide access to data to meet security requirements
Implement for high availability, disaster recovery, and global distribution
Manage data security:
Implement data masking
Encrypt data at rest and in motion
Develop batch processing solutions:
Develop batch processing solutions by using Hive and Spark transformations
Ingest data by using Sqoop
Create linked services and datasets
Create oozie workflow pipelines and activities
Create and schedule jobs
Implement Cloudera Spark clusters, jupyter notebooks, jobs, and autoscaling
Ingest data into Cloudera HDFS
Develop streaming solutions:
Configure input and output with Kafka
Select the appropriate windowing functions
Implement event processing by using Spark Streaming /Kafka
Ingest and query streaming data using Spark
Monitor Cloudera Services:
Monitor Cloudera Cluster and its services like Spark, Oozie workflows, HDFS, Hive etc
Optimize Cloudera data solutions:
Troubleshoot data partitioning bottlenecks
Optimize HDFS Storage
Optimize Spark Streaming Analytics
Optimize Hive/Impala Analytics
Manage the data lifecycle
What You Have
5-10+ years in IT
2-3+ years in Cloudera and Hadoop Ecosystem
Experience in Agile or PMI methodology managed projects
Experience in enterprise applications, solutions and data infrastructures
Experience in designing of data management solutions
Experience in designing of robust CI/CD solutions
Python/PySpark (highly desired)
Java/Scala
Apache Hadoop HDFS, Map Reduce
Oozie
Hive
Cloudera Impala
Spark
Kafka
Spark Streaming
Yarn
Sqoop
Git, GitLab, Artifactory
ADO
Certifications:
SCRUM Developer
Big Data Hadoop certification
What We Offer
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance",3
"NO THIRD PARTY RESUMESJob Title: Data Analyst/Report Writer ILocation: Glendale Milwaukee WI 00001Duration: 6 Months Contact W2Description:Job Description: Transformation Data AnalyticsWhat you will doTransformation Data Analytics will be part of the Transformation Office reporting to the Transformation Office Director and Program Manager. You will apply your data engineering skills to solve real-life, complex problems and deliver long term sustainable impact. You will work with Transformation Program Management Team to set-up and execute a best in class Transformation Office and the related Performance Infrastructure. You'll build business, optimization, and financial models and deploy Transformation tools drawing upon various analytics techniques e.g., Excel, VBA, Tableau, SQL, Alteryx, Power BI, M, DAX etc. You will also enable best in class deployment of Transformation management tools and enable effective cadence planning, impact capturing, and program management. You will be responsible for database hygiene – providing quality control checks and proactively fixing issues; act as the primary point of contact for custom data requests, oversee any changes to the back end of the databases; and be responsible for regular database updates.How you will do itYou will work hand in hand with Transformation Office leadership, Workstream members, and Wave champions to ensure seamless delivery of dashboards and reports. Provide guidance and leadership to teams on analytics, build Workstream capabilities. Produce, maintain, and distribute the Transformation Office reports for all Workstreams. Conduct ad hoc analyses as requested, proactively searching for opportunities to deliver additional insights to members of the Transformation Office and Executive Committee. Be the first point of contact for Transformation participants with data questions. Have a complete understanding of the data and its structure, and provide coaching as necessary.Provide data and analytical support for the creation of financial and operational analyses supporting transformation and ongoing strategic plans and other documents.Required QualificationsUndergraduate or Graduate degree, preferably in Computer Applications, Engineering, Business Management, Mathematics, Operations researchStrong data modeling and data visualization skills across a range of platforms including 1) Excel and Excel VBA, 2) PostgreSQL or similar data engineering platforms, and 3) PowerBI (including DAX and M languages with at least 3 years of experienceExcellent analytical and problem-solving skills, including the ability to disaggregate issues, identify root causes and recommend solutionsKnowledge of fundamental business concepts, operations research and statistical techniquesDetail oriented and with ability to work under pressure, mentally resilient to endure the long and tough road of a transformationFlexibility, patience, and an understanding of fluid, demanding, and unstructured environments where priorities evolve constantlyHighly pragmatic, focused on achieving outcomes and impactEntrepreneurial and proactively thinking about potential improvements to how things are donePrevious work experience in building business algorithms, scenario planners, solving business problems using optimization techniques and running project management offices is preferredPassion for/attention to detailAbility to work effectively in a high pace environmentBasic software engineering project management experience in Agile, Lean, or Scrum development is a plus (in particular defining requirements, rapidly iterating and deploying features)Desires to accelerate their career path through a challenging and rewarding experiencePlease fill the details for Submission:Legal name:Contact no:Email id:Visa status:Current location:Relocation:Availability:End date of recent project:Linked in:Pay Rate Expected:Thanks&RegardsVenkat KothaTrigent Software Inc2 Willow Street, Suite #201 Southborough, MA 01745508-779-6728venkat_k @ trigent.comJob Type: ContractSalary: $29.00 to $35.00 /hourExperience:business analysis: 1 year (Preferred)data analyst: 1 year (Preferred)analytics: 1 year (Preferred)sql: 1 year (Preferred)data analysis: 1 year (Preferred)Benefits:None",0
"Category: Administrative/Staff

Department: Information Technology

Locations: Springfield, MA

Posted: May 4, 2020

Closes: Open Until Filled

Type: Full-time

Ref. No.: 2432


About American International College:
American International College is a private, coeducational institution of higher education located on a 70+ acre campus in Springfield, Massachusetts. The campus has 42 buildings on two sites approximately 1/2 mile apart with a total of approximately 660,000 gross square feet. Included in the inventory of buildings are student residences for a resident population of 900 students. Founded in 1885, the College has approximately 3200 graduate and undergraduate students. AIC offers a variety of undergraduate and graduate programs through the Schools of Business, Arts and Sciences; Health Sciences; and Education. The mission of the College is to transform student lives through career focused learning, with a strong foundation in the liberal arts, a commitment to serving the community, and a high level of involvement in the global economy.
AIC strives to create a diverse and inclusive campus community that is representative, at all job levels, of the students we serve. We are an EEO employer and we welcome applications from individuals for positions where they are underrepresented.

Job Description:
Develop, implement, and maintain systems to document and report on data
Work with and enhance data integration procedures, policies and publish to the College community via the Data Management Team
Create a strategy that will manage the data integrations environment and communications for College departmental and data management committee use.
Review and assist system and user documentation production by offices.
Continually analyze technologies, technical processes and/or functions as they relate to key performance metrics or executive dashboards.
Participate in data validation for regular internal and external reports and surveys
Support the ongoing assessment and effective utilization of data for planning, policy-making, and program improvement
Work with the College in defining key performance indicators
Produce statistics, analyses, reports, and reviews relative to internal and external requests for data
Compile, analyze, and disseminate quantitative data on facets of the College and related educational issues, including institutional characteristics, enrollments, student retention, student transfer activities, enrollment projections, grades, other student performance indicators and fiscal affairs

Requirements:
Required Degree(s): Bachelor's degree
Preferred Degree(s): Master's degree
Required Field of Expertise: Business Analytics, IT, Data Analytics; Minimum 5 years of experience in quantitative and qualitative research, statistical analysis, and reporting
Preferred Field of Expertise: Higher education
Knowledge/Skills/Abilities
Knowledge of current trends and issues relating to federal and state reporting; accreditation requirements; current and innovative practices in the development and assessment of institutional effectiveness and student learning outcomes; current theory and practice in institutional research; the development of assessment tools and methods of measurement; research design; data warehousing, management information systems
Ability to collaborate effectively with College offices and administration, seek consensus on outcomes, and apply bench-marking techniques.
Must possess excellent computer skills and familiarity with Higher Education Enterprise Systems and, SQL and data analysis software tools

Additional Information:
This is a full time, exempt level, benefit eligible position. Normal business hours are Monday through Friday, 8:30am - 4:30pm, flexible to the needs of the department. Night and weekend work may be required.

AIC is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

Application Instructions:
Qualified applicants should save and submit the following documents with the online application.
Brief cover letter
Current resume
Contact information for three professional references (one of which must be a current or prior supervisor)
Review of applications will continue until the position has been filled.",0
"Tripoint Solutions is seeking a Business Analyst with a strong data management background for a position located at our Huntsville, AL office.
This role is focused on maintaining operational data integrity, automated solutions, and visualizations for business processes reports. The Business Analyst will implement methods to evaluate the efficiency of complex data integrity, business operations, and software. You’ll work as part of a team with a highly engaged client that is focused on an environment of constant improvement and innovation. Proficiency in Oracle DB Server, MS SQL Server, Qlik Sense is required.
Job Location: Huntsville, AL
The successful candidate will be accountable to:

Conducting in-depth research and analysis of business and data management customer's needs.
Processes and systems for the company's support functions.
Analyzing possible technology solutions and assessing benefits, risks, costs, and technology architecture needs.
Assisting in planning and evaluating project activities including, project documentation, scheduling, requirements management, deployment readiness reviews, and status updates.
Participating in requirements gathering sessions, translating business requirements to detailed technical system specifications, and serving as the liaison amongst project stakeholders, customer, and team lead.
Participating in establishing quality standards for life cycle, documentation, requirement collection methods, testing, data quality analysis and reporting.
Research and content of business process planning and documentation.
Assisting in developing functional and non-functional software requirements.
Assisting in establishing quantitative measurements and techniques for measuring software quality.
Reviewing and evaluating software products and services for adherence to government directives, standards, and guidelines concerning software quality assurance.
Work closely with delivery managers to define, prioritize and solve complex business problems.
Creating data logic workflows, flowcharts, diagrams, and other documentation.
Creating, validating, and augmenting data management documentation on the configuration, infrastructure, and processes associated with the production environment (e.g., Oracle DB Server, MS SQL Server, etc) environment.
Deploying and testing database patches, maintenance jobs, and change scripts in non-production environments.
Proactively identifying tactical risks in the database environment and raise/resolve issues efficiently.
Required Skills
Data analysis and quality experience
Analytical ability
Ability to facilitate meetings and collaboration sessions with customer
Ability to quickly learn new concepts and software
Strong communication skills (both written and verbal)
Effectively communicate complex information
Proficiency in JIRA/ Confluence (Atlassian), MS Office Suite and G Suite (Docs, Drive, etc.).
Proficiency in Oracle DB Server, MS SQL Server, Qlik Sense
Experience, Education & Training:

Bachelor’s Degree with 2-4 years of experience. Or 7-9 years of experience in lieu of degree.
Proficiency in Oracle DB Server, MS SQL Server, Qlik Sense

Clearance Requirements
Applicants selected may be subject to a government security investigation and must meet eligibility requirements for potential access to classified information",0
"Please Note That We Do Not Offer SponsorshipScale is a tech-driven direct-to-consumer company that builds and deploys next-generation CPG brands in the beauty, health and wellness industries. Through our proprietary eCommerce and digital marketing engine, Scale transforms consumers’ end-to-end online shopping experience while increasing brand loyalty and retention. Scale’s growing portfolio of five brands and 70+ products helps hundreds of thousands of people live healthier lives.*Together we have a lifetime of experience in health, nutrition, entertainment, advertising, creative, media buying, strategy, performance optimization, and leadership. We have achieved success that has resulted in thousands of lives changed and millions of dollars in revenue.We are searching for a Marketing Data Analyst to join our growing Business Analytics team.Use your data and analytical skills to help develop data and marketing models for existing and new products, new acquisition channels and different marketing efforts. You will have the opportunity to expand your skills and knowledge by collaborating with our awesome internal and external teams.**We are looking for someone with a natural ability to use data to better understand customer behavior, and use those findings to improve business results including future forecasting, predictive analysis, subscriptions and retention.**Responsibilities: Conduct in-depth evaluation and analysis of marketing programs to help derive insights and recommendationsAnalyze and aggregate the effectiveness of customer acquisition campaigns using a variety of sourcesGather information and examine web traffic, social media metrics, marketing campaigns and other activities that will design and create reports for a variety of stakeholdersCreate and manage the company’s online BI tool, including dashboard creation, using complex data from different data sources, such as our data warehouse and other API’sPresent monthly, quarterly and yearly results to the executive team, as well has provide business insights and assist with strategic planningCollaborate with media teams to provide data insights and recommendations for optimization towards marketing goals, campaign ad spend, and campaign funnels across digital channelsAnalyze and optimize current retention efforts to reduce churn rates, provide key insights and derive new retention plans and offerings across different products and brands.Create revenue projections for the company’s product lines, derive specific targets per department based on projections.Education Requirements: Bachelor’s degree in business, statistics, math, IT or a related fieldExperience Requirements: Preferred min. 5 years’ experience in a related field such as eCommerce, Digital Marketing or CPGExcellent SQL and Excel knowledge and experiencePreviously experience in a Data Analysis / Statistics / Business Analytics rolePreviously experience in a Data Visualization tools development (data modeling as well as dashboard design) such as Sisense, Tableau and Qlik.Demonstrated experience with statistical software would be an advantageWhy You Should Join Scale: At Scale you’ll be joining our existing team of skilled and passionate professionals. We’re always trying to push the envelope with how we can use technology to drive business processes. We collect and process large amounts of data to inform business decisions on a daily basis. We are constantly optimizing and improving the user experience we provide our customers.If this sounds like a challenge you are up for, we would love to hear from you!What We Offer: Competitive Salary Commensurate with Years of ExperienceMedical, dental, vision and life insuranceGym MembershipOffice SnacksYoga, meditation and dance breaksCasual DressCompany OutingsPaid time offPlease Note That We Do Not Offer Sponsorship*Job Type: Full-timeSalary: $27.00 to $34.00 /hourBenefits:Health insuranceDental insuranceVision insurancePaid time offWork from homeFlexible scheduleSchedule:Monday to Friday",0
"Manages data throughout all stages of the data analysis lifecycle, including obtaining novel data from external and sometimes untraditional sources, managing and coordinating the collection and utilization of data across diverse data platforms, cleaning and transforming data of widely varying formats, and providing meaningful insights and actionable analytics. Works with both structured and unstructured data, transforming data to ensure consistency and accuracy across data systems, automating resource-demanding data processes, and creating visualizations and reports. Provides administrative support relative to these activities.
PRIMARY RESPONSIBILITIES
Uses machine learning to mine data from clinical databases.
Parses, validates, and scrubs data of different formats (structured and unstructured) to ensure the integrity of clinical data.
Implements visualizations of data that are user friendly, easily interpreted, and actionable.
Develops creative and analytically driven solutions by employing statistical and machine learning techniques.
Designs experiments, collects data, performs statistical analysis, and presents solutions to improve clinical care.
Automates resource-consuming and repetitive tasks by writing reusable code for speeding up the delivery of commonly-made requests related to fetching, summarizing, transforming and visualizing data.
Develops, evaluates, implements, maintains and enhances predictive models and processes.
Performs other duties as assigned.
EDUCATION
Bachelor’s degree in business or health care, Associate’s degree, or high school diploma or equivalent
EXPERIENCE
Three years’ relevant experience with a Bachelor's degree; seven years' relevant experience with an Associate's degree; or one year of additional schooling/training and ten years of relevant experience with a high school/equivalent
PHYSICAL REQUIREMENTS
Frequent lifting/carrying and pushing/pulling objects weighing 0-25 lbs.
Frequent sitting, standing, walking, reaching and repetitive foot/leg and hand/arm movements.
Frequent use of vision and depth perception for distances near (20 inches or less) and far (20 feet or more) and to identify and distinguish colors.
Frequent use of hearing and speech to share information through oral communication. Ability to hear alarms, malfunctioning machinery, etc.
Frequent keyboard use/data entry.
Occasional bending, stooping, kneeling, squatting, twisting and gripping.
Occasional lifting/carrying and pushing/pulling objects weighing 25-50 lbs.
Rare climbing.",0
"Machine Learning Engineer
US Citizenship is required due to security clearance requirements.
Are you a motivated engineer who is passionate about embracing new challenges and solving the hardest technical problems in a team-oriented environment? Every day, the engineers at Expedition Technology work together to solve our Nation’s defense and intelligence challenges by using Machine Learning and Deep Learning to demystify data obtained from signals and images.
Our applied research and development mindset afford our people the opportunity to work on the most cutting-edge methods of optimizing deep learning networks, developing state-of-the-art algorithms and ultimately producing software products that are critical to our nation’s defense infrastructure.
The success we have already achieved has made Expedition Technology one of the top Machine Learning/Deep Learning research organizations in the Defense and Intelligence communities and we need additional intelligent, passionate, creative people to join our team.
When you join our team, you’ll have the opportunity to:
Dive directly into the latest computer vision and signal processing research to replicate new techniques published in academia and find ways to make those ideas work on a larger scale
Use your strong Python coding skills to research, design, develop and expand upon algorithms that will train neural networks to deliver actionable intelligence faster and more effectively
Develop deep-learning software prototypes that demonstrate potential usefulness to our customers
Analyze data from disparate sources including images, video, radar, signals and more
Brainstorm solutions to the toughest problems alongside a team of smart, creative, passionate engineers
Participate in machine learning brownbag sessions and other forms of collaborative learning to keep abreast of the constant changes in Machine and Deep Learning
Required skills:
Strong problem-solving skills combined with deep intellectual curiosity and the desire to push technical boundaries
Strong coding skills- preferably in Python, C/C++, Julia or other object-oriented language in a Linux environment
Software development skills and the desire to work on cutting edge development in a Cloud environment
Deep understanding of data structures and algorithms
Knowledge of computer vision and/or signal processing including techniques for classification and feature extraction
Excellent oral, written, presentation and communication skills
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field. Advance degrees welcome
US Citizenship- Must be a US Citizen eligible to maintain a US Government security clearance
Desired skills:
Experience with deep learning frameworks like Tensorflow, PyTorch, Caffe or Keras
About Expedition Technology
At Expedition Technology, we push the boundaries of what is possible every day. Our engineers work on the most challenging problems in Computer Vision, Digital Signal Processing and Software Engineering from a Machine Learning/Deep Learning perspective and collaborate to find the answers. We are a research-focused company whose mission it is to solve our customer’s most pressing needs in a creative, novel manner.
Expedition Technology offers self-directed, company-paid Medical, Dental and Vision benefits and the freedom to allow you to select which benefits matter most. We offer a 401k with a generous company match, a student loan repayment program, equity shares, paid holidays, paid time off and an education reimbursement allowance. Most importantly, we offer an environment where we are encouraged to push boundaries, take risks and enjoy the rewards.
Interested in joining our team? Let’s explore together.
EXP is proud to be an Equal Opportunity Employer that believes a diverse range of talent creates an environment that fuels creativity and innovation. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, genetic information or protected veteran status.
Powered by JazzHR
RulcrBlqJf",2
"Healthgrades is focused on providing trusted information that helps consumers and providers make meaningful connections. As a Senior Data Engineer, you will be building the future of Healthgrades' enterprise data solutions, enabling health systems, hospitals and providers to better reach those consumers who are seeking care.

The Healthgrades enterprise data platform will enable health systems to create a holistic patient view, eliminate data silos, and improve patient experience. This enterprise platform will bring together once disparate data into a single platform, breaking down data silos and making data more useful across an entire organization. The Healthgrades data platform will also serve as the underlying data management solution for powering Healthgrades CRM and other customer experience execution systems while enabling health systems to reach beyond traditional efforts to improve and manage patient experience and patient engagement.

 If you are a technologist and your idea of fun is to play with the latest technology, while delivering a world-class product designed from scratch, you will fit right in.


What You Will Do:
Work with a team of engineers to create products that will directly affect the mission of Healthgrades
Develop data pipeline features to process incoming healthcare information quickly and reliably
Review other team members' code for correctness and quality
Write automated test scripts that power a continuous delivery pipeline
Refactor and improve the existing code base for simplicity and clarity
Remove roadblocks to development through collaboration, communication, and creative solution recommendations
Recommend and drive development best practices and continuous integration and delivery as part of a forward-thinking, agile organization
 What You Will Bring:
5+ years of experience developing data pipelines or ETLs
5+ years of experience in Python, Scala or Java
Strong understanding of SQL, relational databases, columnar data warehouses, and data modeling
Knowledge of TDD, automated testing principles, and testing best practices
Ability to instrument basic automation and CI/CD including a familiarity with Jenkins/Git
Strong familiarity with cloud based services (AWS) and container technologies (Docker/Kubernetes)
Experience working with Apache Spark for data transformation & aggregation
Proficiency with Databricks, and Alteryx is desired
Previous experience with micro services architecture and API gateways is a plus
Knowledge (and experience) designing and building distributed systems for scalability and security
A bias towards self-education of new technologies, techniques and methods
Test-and-learn mentality – you pivot quickly when an approach is not successful
Keen attention to detail, eye for design and understanding the value of collaboration with UX/creative and product teams


Why Healthgrades?

At Healthgrades, we recognize that our people drive our greatest achievements. We are passionate about maintaining a fulfilling, rewarding and high-energy work environment while setting the stage for your continued success.

Meaningful Work – empowering consumers with data to make the right decisions for themselves and their families
Changing the Game - evolving, dynamic culture with career advancement opportunities
Community Builders- participating in local charity organizations and wellness initiatives
Robust Perks – generous PTO, 401k contributions, tuition assistance, entertainment discounts & more!",3
"Company OverviewMachine learning is changing the way the world does business. Recommendations are smarter than ever, and predictions are closer to reality. But is it good enough? Many predictions are still off-mark, and companies are missing opportunities to deliver stellar customer experiences and drive down costs with ad hoc data infrastructure and ML processes. At Kaskada, we are revolutionizing enterprise machine learning through the use of real-time data. Our team is delivering an end-to-end machine learning platform powering feature engineering and productionization.Job SummaryLove solving challenging machine learning problems? Interested in using your skills across industries and use cases? Want to have a huge impact on product and customer success? Kaskada’s lead data scientist role has a unique opportunity to shape our core product, advise the development team, and work directly with customers on challenging data science problems.The perfect candidate has deep data science experience and loves getting hands-on with data and feature engineering. This person is excited to share their passion for data science with others through working directly with customers, teaching and mentoring other data scientists, and sharing the results of challenging machine learning with the world. This role is part of the founding product team at Kaskada and will have enormous impact on the success and direction of the company and product.ResponsibilitiesConsult enterprise data science teams: Help our customers and prospects solve their machine learning problems and get to success on the Kaskada platform. You will work directly with data science teams across a wide range of industries to understand their projects, advise them on the best approach, and gather feedback and requirements. This part of the role will expose you to cutting-edge machine learning projects at Fortune 500 companies and span a wide range of use cases ranging from predictive pricing to search and ranking to fraud detection to smart devices.Be our internal product expert: Work hand in hand with product, UX and engineering to define requirements for our machine learning platform through building POCs and experiments and by representing customer needs. Identify areas of potential product development or roadmap gaps through personal experience, customer feedback and industry trends. This part of the role will influence strategic product and business decisions across the company.Evangelize to data scientists and data engineers: Run ML experiments and share your ideas with the world through blog posts, white papers, webinars, and more.Build out a grass-roots following and grow brand awareness by engaging with other data science and big data influencers.About you5+ years of data science experience building machine learning models and features (combination of industry and academic experience is OK). Data Engineering experience is a plus.BA/BS in Computer Science, Math, Statistics, Engineering, Physics, or another technical field. Masters degree or PhD is a plus.In-depth understanding of machine learning using event-based data and manipulating large data sets.Experience and knowledge in using SQL and Python for machine learning.Enjoy working with customers and can quickly build trust and credibility.Love to blog and create content for your areas of expertise.Passion for teaching and mentoring other data scientists.Strong written and spoken communication skills.Passionate about building products that have real customer impact.Full of good ideas and not afraid to share them.Have a strong desire to be part of a small, lean and growing team.BenefitsKaskada is a Seattle-area startup building a machine learning platform for event-based data. We are a team of doers with leadership roots from Google and AWS. We are actively building a team of other top performers to join the fun. The company is funded by leading PNW and Bay-area VCs, including Voyager Capital, NextGen Venture Partners, Founders’ Co-op, and Bessemer Venture Partners.Kaskada offers competitive salaries including equity. Employees are also eligible to receive benefits including health insurance, dental, and vision insurance; life insurance, 401(k) plan, and more.Apply for this positionREQUIRED*Apply with IndeedAPPLY WITH INDEEDFirst Name*Last Name*Email Address*Phone*AddressResume*Attach resume or Paste resumeSUBMIT APPLICATIONJob Type: Full-timeSalary: $0.00 /yearExperience:Data Science: 5 years (Preferred)Application Question:Have you done Machine Learning with event based data sources previously?Additional Compensation:Other formsWork Location:One locationBenefits:Health insuranceDental insuranceVision insurancePaid time offFlexible scheduleRelocation assistanceCompany's website:www.kaskada.com",1
"About EAB

At EAB, our mission is to make education smarter and our communities stronger. We harness the collective power of 1,600+ schools, colleges, and universities to uncover and apply proven practices and transformative insights. And since complex problems require multifaceted solutions, we work with each school differently to apply these insights through a customized blend of research, technology, and services. From kindergarten to college and beyond, EAB partners with education leaders, practitioners, and staff to accelerate progress and drive results across three key areas: enrollment management, student success, and institutional operations and strategy.

At EAB, we serve not only our partner institutions but each other—that's why we are always working to make sure our employees love their jobs and are invested in their community. See how we've been recognized for this dedication to our employees by checking out our recent awards.

For more information, visit ourCareers page.

The Role in Brief:

Senior Data Engineer

Are you a data enthusiast who seeks to tease out meaning from complex data flows and assets? Are you a talented problem solver who can transform abstract problems into elegant technical solutions? We are looking for a Data Modeler to join our team of engineers and data analysts focused on designing, creating, and delivering data solutions as part of our state-of-the-art cloud based products. The successful candidate will have the opportunity to build a world-class solution to help our higher education partners solve challenging problems through data.

This role is based in Washington, DC.

Primary Responsibilities:

Responsible for data modeling and schema design that will range across multiple business domains within higher education
Partner with multiple stakeholders including partners, new product development, BI engineers to develop scalable standard schemas
Work with partners to research and conduct business information flow studies
Codify high-performing SQL for efficient data transformation
Coordinate work with external teams to ensure a smooth development process
Support operations by identifying, researching and resolving performance and production issues
Mentor and coach junior data engineers on data engineering foundations and best practices
Lead small team on data feature development including scoping, design, delegation of tasks, and rollout

Basic Qualifications:

5+ years of experience working with relational or multi-dimensional databases
Experience developing logical data models within a data warehouse
Experience developing ETL processes
Demonstrated mastery in one or more SQL variants: PostgreSQL, MySQL, Oracle, SQL Server, or DB2
Demonstrated mastery in database concepts and large-scale database implementations and design patterns
Proven ability to work with users to define requirements and business issues
Excellent analytic and troubleshooting skills
Strong written and oral communication skills
Bachelor’s degree in Computer Science or Computer Engineering

Ideal Qualifications:

Experience working in an AGILE environment
Experience developing commercial software products
Experience with AWS data warehouse infrastructure (redshift, EMR/spark)
GIT expertise
Master’s degree in Computer Science or Computer Engineering
Experience using Python or other language to develop custom scripts against APIs to extract data
Experience with APIs

Benefits:

Consistent with our belief that our employees are our most valuable resource, EAB offers a competitive and inclusive benefits package.

Medical, dental, and vision insurance; dependents and domestic partners eligible
401(k) retirement plan with company match
20+ days of PTO annually, in addition to paid firm holidays
Daytime leave policy for community service or fitness activities (up to 10 hours a month each)
Paid parental leave for birthing or non-birthing parents
Phase Back to Work program for employees returning from parental leave
Infertility treatment coverage and adoption or surrogacy assistance
Wellness programs including gym discounts and incentives to promote healthy living
Dynamic growth opportunities with merit-based promotion philosophy
Benefits kick in day one, see the full details here.


At EAB, we believe that to fulfill our mission to “make education smarter and our communities stronger” we need team members who bring a diversity of perspectives to the table and a workplace where each team member is valued, respected and heard.

To that end, EAB is an Equal Opportunity Employer, and we make employment decisions on the basis of qualifications, merit and business need. We don’t discriminate on the basis of race, religion, color, sex, gender identity or expression, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law.",3
"The Department of Public Health Sciences is a large, complex teaching and research department in the UC Davis School of Medicine. Our mission is to improve the health of people through population-based approaches by carrying out educational programs, epidemiologic research, public service and policy development. CHARGE (CHildhood Autism Risk from Genes & Environment), ReCHARGE (Revisiting CHARGE participants) and MARBLES (Markers of Autism Risk in Babies-Learning Early Signs) are epidemiologic investigations of underlying causes for autism based in the Department of Public Health Sciences. CHARGE is the first to examine a broad array of environmental exposures along with genetic factors; ReCHARGE is following up the children who were seen at ages 2-5, as they reach late childhood or adolescence; MARBLES is the first prospective study that starts during pregnancy and is seeking to identify both the environmental exposures and early biologic markers of autism risk.
Job Summary
Final Filing Date : 3/20/20
Salary Range : $26.05 to $52.30
Salary Frequency : Hourly
Appointment Type : Career
Percentage of Time : 100
Shift Hour : Day
Location : Public Health Sciences, 1616 DaVinci Court
City : Davis
Union Representation : No
Benefits Eligible : Yes
We offer exceptional employment benefits including medical, dental, and vision plans, generous paid vacations and holidays, excellent retirement savings and investment plans, continuing education, and reduced fee and scholarship programs.
THIS IS NOT AN H1- B OPPORTUNITY
Responsibilities
This full-time, career position will provide general support to users of the CHARGE, MARBLES and/or ReCHARGE Study databases, which include graduate students, post-doctoral scholars, and collaborators both within and outside UCD. The Research Data Analyst 2 will work with a team of Programmers/Data Analyst under the supervision of the lead Programmer and PI. The Research Data Analyst 2 will assist in maintaining electronic SAS databases, cleaning the data, and providing statistical summaries; this will include developing and updating codebooks, importing and exporting files from various platforms/operating systems, identifying erroneous or questionable data, cleaning variables for analysis, and creating analytic variables. Additional responsibilities may include querying the database for the specimen repository, conducting data analysis, performing basic statistics, and creating charts and graphs.
Required Qualifications
A minimum of one year of experience working with intensive data cleaning and management required.
At least one year of experience with the SAS Statistical Analysis Software and demonstrated knowledge of basic SAS required.
Demonstrated skills and experience documenting data management activities required.
Experience working with large datasets, complex research programs, or similar environment preferred.
Experience writing code to provide descriptive analysis of data.
Demonstrated knowledge of basic summary statistics and how to interpret them.
Familiarity with biomedical research.
Skills and experience to maintain data codebooks preferred.
Expereince explaining details regarding databases and protocols.
Ability to juggle several responsibilities and projects, and under general supervision, prioritize different projects or tasks.
Good skills and experience in communication with persons from a variety of backgrounds, such as field staff, clinicians, and scientists from various disciplines.
Excellent organizational, analytical and problem-solving skills.
Preferred Qualifications
Bachelor’s degree or extensive coursework in statistics, applied mathematics, or closely related field, preferred.
Experience preparing and exporting data for use by other analysts and researchers preferred.
Special Requirements
To meet project deadlines, occasional overtime or evening/weekend work may be required.
This position may be subject to a criminal background investigation, drug screen, Live Scan fingerprinting, medical evaluation clearance, and functional capacity assessment.=
EEO
The University of California is an Equal Opportunity/Affirmative Action Employer advancing inclusive excellence. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or other protected categories covered by the UC nondiscrimination policy.",0
"About Spin
Spin operates electric scooters in cities and campuses nationwide, bringing sustainable last-mile mobility solutions to diverse communities. Recognized for its consistent cooperation and collaboration with cities, Spin partners closely with transportation planners, elected officials, community groups, and university administrators to bring stationless mobility options to streets in a responsible and carefully orchestrated manner.

Based in San Francisco, Spin is a diverse team of engineers, designers, urban planners, policymakers, lawyers and operators with experience from Y Combinator, Lyft, Uber, local and federal government, and the transportation advocacy world. Spin was known for launching the first stationless mobility program in Seattle, and has since expanded to become the exclusive electric scooter partner in mid-sized cities like Coral Gables, Florida and Lexington, Kentucky, and one of a few permitted scooter operators in large cities like Denver, Detroit, and Washington, D.C. The team embeds in cities and neighborhoods to understand their specific transportation needs, and hires locally from the community.

Spin is expanding quickly and looking for top-tier talent to help us bring affordable and accessible transportation options to cities and define what future safe streets will look like.

About the Role

Being a data informed company, data helps us create exceptional experience for our customers and provide insights into the effectiveness of our product.

We are looking for Data Engineers that will build and maintain our data warehouse and data pipelines, collect data from multiple sources, and expose services that make data a first class citizen at Spin. You will be building, architecting and launching highly reliable and scalable data pipelines to support data processing and analytics needs. Your efforts will allow access to business and user behavior insights.

The Team

Our engineering team consists engineers that are passionate about creating finely polished and intuitive experiences and, at the same time, obsess over performance and reliability of what we build. We challenge the status quo and strive towards finding the best way to solve problems.

We promote being a more well rounded engineer by working on different parts of the engineering stack. We also work in very small groups to keep processes and overhead low, so we have a lot of trust and accountability to perform the work required to build the best product.
Responsibilities
Build and maintain our data warehouse and data pipelines
Scaling up our data infrastructure to meet business needs
Deploy sophisticated analytics programs, machine learning and statistical methods
Work cross-functionally with our product, business, finance and engineering teams
Qualifications
Minimum of 3 years of relevant experience in building and architecting data solutions
Deep understanding of distributed systems
Expert in SQL and high-level languages such as Python, Java, or Scala
Built and maintained data warehouses and ETL pipelines
Experience with Data modeling
You have worked with big data solutions like Redshift, Snowflake, Hadoop or Hive
Experience with realtime data streaming infrastructure like AWS Kinesis, Spark or Kafka
Worked with Cloud-based architecture such as AWS or Google Cloud
Benefits & Perks

Opportunity to join a fast-growing startup and help shape and establish the company’s industry leadership
Competitive health benefits
Daily catered lunch in our SF office
Unlimited PTO for salaried roles
Commuter stipend plus pre-tax benefits
Monthly cell phone bill stipend
Wellness perk for salaried roles

Spin is an equal opportunity employer and will not discriminate against any employee or applicant for employment in an unlawful matter. We celebrate diversity and are committed to creating an inclusive environment for all individuals. Spin treats all employees and job applicants on the basis of merit, qualifications, and competence without regard to any qualified individuals' sex, race, color, religion, national origin, ancestry, gender (including pregnancy, breastfeeding, or related medical condition), sexual orientation, gender identity, gender expression, age, physical or mental disability, medical condition, genetic characteristic or information, marital status, military and veteran status, or any other characteristic protected by state or federal law. Spin also considers qualified applicants with criminal histories, consistent with applicable local, state, and federal law.

Spin is committed to providing reasonable accommodations for qualified individuals with disabilities in its job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at job_accommodations@spin.pm.",3
"Organization and Job ID
Job ID: 310763
Directorate: National Security
Division: Computing and Analytics
Group: Software Engineering and Architectures
Job Description
Do you want to create cutting edge software and data technologies while working on the nation’s hardest problems? Do you enjoy engineering new data processing capabilities against large volumes of streaming data? Then consider a Senior Data Engineer position in the Software Engineering and Architectures Group at the Pacific Northwest National Laboratory (PNNL), where you will join a team of talented and dedicated professionals working in the areas of energy, the environment, and national security.
This Senior Data Engineer – Data Streaming position will focus on applying the latest in large-scale data streaming technologies to PNNL sponsor problems. This will include engineering cloud-scale data pipelines against high velocity and variety data streams and then integrating these with real-time analytics and machine learning capabilities.
The ideal candidate is a software engineer with substantial Data Streaming experience who understands the methods and pitfalls of working with Big Data. They build data pipelines that source and transform the data into the structures needed for analysis. These data pipelines must be well engineered for performance and reliability. This requires a strong understanding of software engineering best practices. Data engineering also uses monitoring and logging to help ensure reliability. They must design for performance and scalability to work with large data sets and demanding SLAs.
The ideal candidate will also possess qualities such as,
An interest, curiosity and technical depth to support the development and advancement of a variety of applied problems specific to the national security community

The ability and the desire to learn new technologies in this rapidly evolving field

Technical knowledge in configuring and deploying applications in multiple environments – cloud, container services, clusters

Excellent verbal and written communication skills

The Senior Data Engineer should have sophisticated working knowledge in several of the following related-skillsets:
5+ years of experience programming in at least one object-oriented programming language such as Python, Java, C#, or C++ Indexing and summarizing large data-sets to enable high-performance analytics

Data pipeline development, in particular for real-time streaming data (e.g., Spark, Apache NiFi, Apache Kafka, Apache Pulsar, AWS Glue, Amazon Kinesis)

Optimizing database queries for efficient real-time processing

Scaling and maintaining cloud, real-time databases and data processing pipelines

Experience with big data platforms

Developing data-driven APIs for machine learning applications

Crafting data normalization models and rules

Leveraging existing open source technologies like ElasticSearch, Hadoop, Spark, PostgreSQL, and other tools

Knowledge of software engineering best practices and software project lifecycles

Experience with cloud platforms such as Amazon Web Services or Microsoft Azure

EXPECTED OF YOU:
Apply knowledge of software engineering practices (e.g. source control, problem tracking, design principles, etc.) with minimal oversight

Take initiative to set personal direction and goals

Stay current about industry developments

Work collaboratively within a team to execute on the full system development life cycle

Maintain or follow quality assurance procedures

Demonstrate good time management skills

Be able to work with different technologies

WHY WE SHOULD TALK:
You want to work in a lively environment full of scientists, engineers, and subject matter experts who love learning and thinking creatively

You want to have impact on people's lives and national security problems

You want to work in an environment where diversity and equality are highly valued

You want to build novel solutions to complex problems

You are independent in your every-day work, and self-directed in your career goal

The hiring level will be determined based on the education, experience and skill set of the successful candidate based on the following:
Level III : Manages small to moderate projects and/or major project tasks. Integrates intellectual and technical capabilities of work teams. Enhances technical/professional skills of junior staff through active mentoring and training. Generates ideas for new proposals and participates in business development activities

Level IV : Manages moderate to large projects and/or major project tasks. Integrates intellectual and technical capabilities of work teams. Enhances technical/professional skills of junior and senior staff through active mentoring and training. Generates ideas for new capabilities and participates in business development activities.

Minimum Qualifications
BS/BA with 5 years of experience MS/MA with 3 years of experience PhD with 1 year of experience

Preferred Qualifications
Bachelor's degree in computer science or closely related field with strong software design and development skills with 7 years' experience, or a master’s degree with 5 years' experience, or a Ph.D. with 3 years experience.

Equal Employment Opportunity
Battelle Memorial Institute (BMI) at Pacific Northwest National Laboratory (PNNL) is an Affirmative Action/Equal Opportunity Employer and supports diversity in the workplace. All employment decisions are made without regard to race, color, religion, sex, national origin, age, disability, veteran status, marital or family status, sexual orientation, gender identity, or genetic information. All BMI staff must be able to demonstrate the legal right to work in the United States. BMI is an E-Verify employer. Learn more at jobs.pnnl.gov.
Please be aware that the Department of Energy (DOE) prohibits DOE employees and contractors from participation in certain foreign government talent recruitment programs. If you are offered a position at PNNL and are currently a participant in a foreign government talent recruitment program you will be required to disclose this information before your first day of employment.
Other Information
This position requires the ability to obtain and maintain a federal security clearance.
Requirements:
U.S. Citizenship

Background Investigation: Applicants selected will be subject to a Federal background investigation and must meet eligibility requirements for access to classified matter in accordance 10 CFR 710, Appendix B.

Drug Testing: All Security Clearance (L or Q) positions will be considered by the Department of Energy to be Testing Designated Positions which means that they are subject to applicant, random, and for cause drug testing. In addition, applicants must be able to demonstrate non-use of illegal drugs, including marijuana, for the 12 consecutive months preceding completion of the requisite Questionnaire for National Security Positions (QNSP).

Note: Applicants will be considered ineligible for security clearance processing by the U.S. Department of Energy until non-use of illegal drugs, including marijuana, for 12 consecutive months can be demonstrated.
Directorate: National Security
Job Category: Engineering/Engineering Techs
Group: Software Eng & Architectures
Opening Date: 2020-04-14
Closing Date: 2020-06-13",3
"Description
Job Description:
Are you sitting down? Ok, good. Here's that opportunity! You know, the one you've been searching for to rapidly advance your career in Intelligence! Our highly visible program supports stakeholders in National Intelligence on a great team of highly-regarded professionals. The lovely area of Bethesda, MD is the location. This program offers very competitive pay $160-200k, and not only provides you with 5 WEEKS of PTO (paid time off), but you also have a ""personal time bank"" that allows you to take time off for personal appointments outside of your PTO, 10 holidays, 10 sick days on day one and each anniversary date (banked if not used), 401(k) matching of 5% with a generous 3-year full vesting schedule!
Wait! There's more...we have flexible start and end work times (Mon-Fri you can work between the hours of 6am and 7pm). The best part of all is....we really care about you and helping you grow your career! Our management communicates regularly and often with you to see how you are doing; if you need help or guidance with anything; if you're ready to take on more responsibility; be promoted; or maybe you're leaning towards trying a new program. We are BIG believers in promoting from within. So much so, we strategically go after similar programs to keep you gainfully employed and hopefully become a Leidos Life-r, as we say. In a nutshell, the opportunities for you to grow here are VAST!
Leidos is seeking a Sr. Data Analyst - Sr. Systems Engineer to support a large customer organization. Position is located in Bethesda, MD. Candidates must currently possess a TS/SCI Polygraph security clearance.
Primary Responsibilities
Responsibilities and tasks may include some or all of the following:
Analyze data related to IT system planning and investment and support requirements to display or visualize the data in a manner that allows a large amount of information to be easily understood.
Review and assess IC implementation plans to identify issues early in the plans.
Develop and review presentation materials to communicate enterprise objectives and goals related to IT systems.
Assist with data and information collection needs to facilitate decision making regarding IC IT investment processes.
Support IT performance measure development and evaluation.
Basic Qualifications
Bachelor's Degree.
Requires 15 years of developing, implementing, integrating, and evaluating systems engineering-related projects and 10 years developing, implementing, integrating, and evaluating IC systems engineering-related projects
External Referral Bonus:
Eligible
Potential for Telework:
No
Clearance Level Required:
Top Secret/SCI with Polygraph
Travel:
Yes, 10% of the time
Scheduled Weekly Hours:
40
Shift:
Day
Requisition Category:
Professional
Job Family:
Systems Engineering
Leidos is a Fortune 500® information technology, engineering, and science solutions and services leader working to solve the world's toughest challenges in the defense, intelligence, homeland security, civil, and health markets. The company's 33,000 employees support vital missions for government and commercial customers. Headquartered in Reston, Virginia, Leidos reported annual revenues of approximately $10.19 billion for the fiscal year ended December 28, 2018. For more information, visit www.Leidos.com.
Pay and benefits are fundamental to any career decision. That's why we craft compensation packages that reflect the importance of the work we do for our customers. Employment benefits include competitive compensation, Health and Wellness programs, Income Protection, Paid Leave and Retirement. More details are available here.
Leidos will never ask you to provide payment-related information at any part of the employment application process. And Leidos will communicate with you only through emails that are sent from a Leidos.com email address. If you receive an email purporting to be from Leidos that asks for payment-related information or any other personal information, please report the email to spam.leidos@leidos.com.
All qualified applicants will receive consideration for employment without regard to sex, race, ethnicity, age, national origin, citizenship, religion, physical or mental disability, medical condition, genetic information, pregnancy, family structure, marital status, ancestry, domestic partner status, sexual orientation, gender identity or expression, veteran or military status, or any other basis prohibited by law. Leidos will also consider for employment qualified applicants with criminal histories consistent with relevant laws.",0
"Company Overview:
WHO WE ARE:

We’re passionate about food and driven by data.


Do you want to impact our future through data, analytics and innovative technology? Do you thrive on leading big things and making it happen? Bring your passion, expertise and problem-solving skills to the table and make an impact.
General Mills is reshaping the future, and technology & data play an important role for us. Your technology experience will help us get the right data and solutions at the right time, every time. As one of the world’s leading food companies,

General Mills operates across the globe with more than 100 recognizable consumer brands, including: Cheerios, LÄRABAR, Pillsbury, Yoplait, Annie’s Homegrown, Totino’s, Epic Provisions and Blue Buffalo.
Job Overview:
WHAT YOU’LL DO
As a Data Engineer, you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling General Mills to advance the data-driven decision-making capabilities of our enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows. In this role you will:

Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals.
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for analytics and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead evaluation, implementation and deployment of emerging tools & process for analytic data engineering to improve our productivity as a team
Develop and deliver communication & education plans on analytic data engineering capabilities, standards, and processes
Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Qualifications:
WHO YOU ARE
Bachelor’s Degree
5 years of experience working in data engineering or architecture role
Expertise in SQL and data analysis and experience with at least one programming language
Experience developing and maintaining data warehouses in big data solutions
Big Data development experience using Hadoop AND some or all of the following: Hive, BigQuery, Impala, Spark and familiarity with Kafka
Experience working with BI tools such as Tableau, Power BI, Looker, Shiny
Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Passion for agile software processes, data-driven development, reliability, and experimentation
Experience working on a collaborative agile product team
Excellent communication, listening, and influencing skills
WHAT’S NICE TO HAVE
Bachelor’s degree in Computer Science, MIS, or Engineering
7+ years applicable work experience
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space
Experience in Python or Scala
Big Data development experience using Hive, Impala, Spark and familiarity with Kafka
Familiarity with the Linux operating system
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Experience with OLAP such as AtScale, SSAS, SAP BW, Essbase
Knowledge of Data Preparation, Data Wrangling, and Feature Engineering

#CB",3
"Located in Malibu, California, HRL has been on the leading edge of technology, conducting pioneering research and advancing the state of the art.

Engineer II – Semiconductor Data Scientist

Education Desired:

Bachelor’s or Master’s degree with a major in Data Science, Computer Engineering, Computer Science, Electrical Engineering, or related science/engineering field

Essential Job Functions:

Develop data analysis and visualization reports and services for semiconductor wafer fabrication and characterization
Work with internal customers to understand data analysis needs and develop creative, efficient, and easy-to-understand reports and software solutions
Utilize existing and to-be-developed data tools to produce reports and provide insights into HRL's semiconductor devices and processes
Assist and train HRL scientists in use of custom data analysis and visualization software
Leverage knowledge of semiconductor fabrication processing to develop dashboard views of SPCs and KPIs for cleanroom modules such as Metals, Dry Etch and Deposition, and Photolithography
Leverage knowledge of AI/ML techniques to identify correlations within large data sets

Experience Desired:

Extensive experience with BI and database-driven reporting/visualization tools such as Tableau
Experience working with customers (internal or external) to generate custom data analysis reports and visualizations
Experience with scientific computing software such as MATLAB
Experience with common AI/ML tools and frameworks such as TensorFlow
Windows and Linux environments
SCRUM project management

Knowledge Desired:

Understanding of semiconductor wafer fabrication processing
Statistics, statistical process control, process control monitoring
Modern regression techniques
Understanding of database structure and querying
Understanding of manufacturing execution systems is a plus

Essential Physical/Mental Requirements:

Good communication skills - Ability to work independently and as part of a team

Special Requirements:

US citizenship or permanent resident status required

HRL offers a very competitive compensation and benefits package. Our benefits include medical, dental, vision, life insurance, 401K match, gym facilities, PTO, bonuses, growth potential, and an exciting and challenging work environment.

This position must meet Export Control compliance requirements, therefore a ""U.S. Person"" as defined by 22 C.F.R. § 120.15 is required. ""U.S. Person"" includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

HRL offers a very competitive compensation and benefits package. Our benefits include medical, dental, vision, life insurance, 401K match, gym facilities, PTO, growth potential, and an exciting and challenging work environment.

HRL Laboratories is an Equal Employment Opportunity employer and does not discriminate in recruiting, hiring, training or promoting, on the basis of race, ethnicity, color, creed, religion, sex, sexual orientation, gender, gender identity, genetic information, national origin, physical or mental disability, pregnancy, medical condition, U.S. military or protected veteran status, union membership, or political affiliation. We maintain a drug-free workplace and perform pre-employment substance abuse testing.",0
"Company Overview:
Integrated Data Services, Inc. (IDS) is a leading provider of custom software products and Government financial management services. IDS was founded in 1997 in El Segundo, CA, and since that time has seen tremendous growth and success. Currently IDS has offices supporting customers nationwide. By providing customers with fast, efficient and reliable information systems and support services, IDS has become a preferred provider of financial and programmatic systems, services, and solutions across a wide variety of government agencies.
Position Description:
IDS is seeking an ambitious self-starter to provide data analytics support for our customers at Wright-Patterson AFB, OH. This position will work with Air Force Life Cycle Management Center (AFLCMC) senior leadership to perform data extraction, cleansing, analysis, visualization and storytelling. Successful candidates will have experience analyzing data from Air Force (AF) systems (Finance, Logistics, Personnel, Acquisition, Contracting, etc.), work well in a collaborative environment, think creatively, thrive under pressure, and be able to adjust to shifting priorities quickly. Candidates will possess effective diplomatic, time management, and oral and written communication skills.
Responsibilities include, but are not limited to, the following:
Gather business requirements, analyze source systems, define underlying data sources and transformation requirements, design data models, and develop metadata for data analysis and visualization.
Acquire and analyze data and metrics across the enterprise to learn how they can be incorporated into data visualizations and dashboards.
Collaborate with business areas and project teams to elicit, identify, prioritize, and document data visualization and business intelligence requirements.
Serve as a functional and technical data visualization and business intelligence subject matter expert.
Translate business analysis and business needs into prototypes concepts of reports and dashboards and contribute to design and visualization best practices.
Utilize business intelligence tools to take dashboard requirements and develop deliverable solutions.
Document data acquisition, data management and data governance processes. Make and implement process improvements and efficiencies.
Create training materials and user guides. Conduct group and one-on-one training sessions with end users.

Knowledge and Skills:
This position requires a minimum of five (5) years of experience in business management.
This position requires a minimum of two (2) years of experience in DoD cost, budget, scheduling or acquisition.
Candidates with experience using Business Intelligence (BI) and self-service data visualization tools such as Qlik Sense, Qlik View, Tableau or Power BI are preferred.
Candidates with Qlik Sense and Air Force experience are preferred.

Education and Work Experience:
This position requires a minimum of a Bachelor's degree from an accredited college or university in business management, engineering, computer science, mathematics, economics or other related discipline.
Experience in lieu of education may be considered if the individual has seven (7) or more years of equivalent technical training or work/military experience.

Certificates and Licenses:
Applicants selected for employment will be subject to a Federal background investigation and must meet additional eligibility requirements for access to classified information or materials.

Travel:
Some travel may be required.

Hours:
Normal work schedule will be 8:00 A.M. to 5:00 P.M., Monday through Friday. May be required to work additional hours and/or weekends, as needed, to meet deadlines or to fulfill travel obligations.

Salary Range:
Commensurate with experience.

IDS offers a robust benefits package including health, dental, vision and 401K plans. IDS is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regards to race, creed, age, sex, gender, physical or mental disability, sexual orientation, gender identity, gender expression, ancestry, pregnancy perceived pregnancy, medical condition, marital status, familial status, color, religion, uniformed services, veteran status, national origin, genetic information, or any other characteristic protected under local, state or Federal law. A submission of a resume is an expression of interest and not considered an application.
For more information, visit www.get-integrated.com.
**U.S. citizenship and/or green card is required; H1-B visas and other visas are not being sponsored. Relocation expenses are NOT compensated. All jobs are employer paid; no fees to candidates. Third parties or agencies inquiries are not being accepted.**",0
"Vida Clinic was awarded a Top Workplaces 2019 honor by The Austin American-Statesman!
You can use your tech skills to support a world-class team of mental health therapists and researchers providing unique, effective services in Texas schools.
Psychology + Technology = Vida Clinic
We are a growing team and there are opportunities for advancement.
The Vida Clinic Story:
We are the largest provider of School Mental Health Clinics in Texas. In 2015 we started operating our first School Mental Health Clinic (SMHC) at a south Austin high school. Vida Clinic's unique SMHCs remove multiple barriers to mental health access, including cost and transportation, while also reducing the stigma of treatment. Our clients quickly experienced measurable improvements in well-being, behavior and academics. Interest in our evidence-based model and measurable outcomes has enabled us to grow rapidly. We now operate over 50 clinics across Texas.
The Vida Clinic Mission:
To operate a Vida Clinic in every school that wants one.
Job Summary:
The Senior Data Engineer will lead our data engineering projects and help us grow our data team. Main responsibilities include RDBMs and big data infrastructure support, input data analysis, database design, importing data, data quality improvement, data report generation, and process improvement. The Data Engineering team will work in collaboration with data analysts and scientists.
We are an agency that values each person and their individual strengths. We offer a supportive environment that encourages and promotes professional growth, drawing upon the unique skills of our employees to contribute to a culture of effective innovation. Since we all are passionate about our work, we have built a culture that enables and rewards efficient and effective processes while promoting a work-life balance. This includes work schedules and employee benefits that encourage personal self-care. This job is based in Austin, Texas.
Vida Clinic Perks:
Join one of Austin's Top Workplaces in 2019
Competitive salary
Comprehensive benefits including medical, dental, vision, and life insurance
Employee Assistance Program and life wellness services
Paid Time Off
Retirement benefits
Plus many more – We have a whole team dedicated to making Vida Clinic an awesome place to work!
What You'll Do:
Infrastructure Support
Manage our cloud-based DB systems including RDBMS and big data systems
Integrate Input Data
Analyze data formats from a variety of systems
Design databases to support reporting and analysis needs
Importing Data
Compiles, scrubs, wrangles, and loads data into databases from a variety of source formats.
Establishes and updates data quality processes
Data Structure Analysis
Conduct detailed analysis of data, including monitoring and ensuring data quality, to be used as input for performance dashboards and reports.
Update database design
Recommend and implement improvements to data quality associated with processes.
Coordinate with stakeholders to improve data quality.
Reporting
Prepare standard and ad-hoc reports, for internal and external audiences.
Ensures accuracy of data included in reports.
Assists in the development and implementation of effective analytic techniques and review methodologies for evaluating and monitoring activities and initiatives.
Coordination
Utilizes strong communication skills to work with team members and partners to improve data input processes.
Coordinates with subject matter experts to ensure accuracy of reports and data input.
Provides routine updates on the status of projects and initiatives.
Identifies and Implements Improvements
Provides suggestions that will improve the collection of data and align data infrastructure with business needs.
Implements ETL processes to reduce manual steps for data acquisition.
Works with operations to improve data collection methods
Required Competencies & Skills
Strong SQL
Understanding of database design and application.
Strong Experience in data preparation, scrubbing, and integration.
Data Wrangling tools.
Data Analysis
Data Pipeline creation
ETL Parameterization
Python or Java
Cloud Database management. Preferably with Google cloud.
Proficient in Google Suite, Microsoft Office Suite or related software
Debugging/Problem Solving
Creativity
Ethical conduct
Flexibility and adaptability
Leadership
Credibility
Effective decision making (whether independently or in collaboration with Vida Clinic team members)
Thoroughness and accuracy
Collaboration skills
Communication proficiency
Effective time management
Organization
Friendly etiquette
Problem solving/analysis
Ability to work independently as well as in a collaborative environment
Preferred Skills
Google Cloud (GCP)
Postgressql
BigQuery
Trifacta Data Wrangling
Google Data Flow ETL
Visual Analysis and reporting (i.e. metabase or google data studio, apache zepplin)
R for statistical analysis
Implementation predictive models and machine-learning algorithms
Vida Clinic provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
yNVd7RpaXp",3
"General Summary:

Elevate is a globally distributed technology firm which develops next-generation financial products focused on managing life’s everyday expenses. The Data Science team conceptualizes, develops, deploys, and maintains predictive models using advanced statistical and machine learning methods. These models are used in Elevate’s Underwriting, Account Management, and Operations applications. The Data Scientist I plays a critical role by applying cutting-edge modeling techniques to drive growth, control risk, and ensure operations excellence.


Principal Duties and Responsibilities:

Design, Develop and Deploy advanced machine learning models for use in Underwriting, Customer Management, Marketing, and Operations.
Assess, clean, merge, and analyze large datasets adhering to standardized data manipulation techniques and methodology by leveraging R, Python and/or Apache Spark.
Perform efficient parallel processing computations both within R as well as cluster computing technologies such as Apache Spark.
Proficiency in multiple linear and nonlinear algorithms for testing, development and deployment into our underwriting engine in the application of risk management in all of Elevate’s acquisition channels.
Efficiently apply data mining methodologies to minimize credit/fraud losses, maximize response and approval rates, and develop methods to enhance profitability of Elevate products.
Assist in the implementation of scoring models on multiple decision platforms Including R instance deployment, On premise deployment and cloud deployment and multiple forms such as Java objects, R Object Models and Apache Spark Models.
Provide knowledge and insight on the third party data providers such as Transunion, Clarity/Experian and Equifax to include knowledge of products and data available, effective use of variables, data dictionaries as well as advantages and limitations.
Maintain clear, detailed model documentation on our Wiki Server by leveraging reproducible research technologies such as Rmarkdown, IPython, Jupyter Notebook, etc.
Interact with business partners to support the needs and goals of all Elevate portfolios, Rock teams, Braintrusts and Pods.


Experience and Education:

Minimum M.S./M.A. in a highly quantitative field (Statistics, Economics, Mathematics, or other quantitatively-oriented degree) required.
At least two years of experience in Data Science, Risk or Modeling for consumer lending; Professional experience waived with Ph.D. Degree in highly quantitative field.
Demonstrated proficiency with advanced statistical modeling and substantial experience with machine learning techniques (e.g., Random Forest, Gradient Boosting, LASSO, Elastic Net, etc.). Knowledge of penalized regression and classification methods a plus.
Solid experience in analyzing, recommending and implementing Risk strategies.
Proficiency of at least two Advanced Statistical Analysis Tools such as R, Python, Scala, Java, SAS, MATLAB, SQL, and/or SPSS; knowledge with versioning software (e.g., Git), big data solutions and data processing frameworks (e.g., Spark, Hadoop).
Experience with at least four database technologies such as MSSQL Server, SAS Datasets, Hadoop, Apache Hive/Impala, Spark, Redshift, HBASE, Kafka, Spark Streaming, Neo4j, Teradata, Oracle, MySQL, DB2, Amazon AWS, Cassandra, PostgreSQL, NoSQL, JSON & XML parsing, etc.
Experience working in fast-paced environment with ever-changing demands.
Good communication skills for communication with Risk Management peers.
Experience in financial services and/or Credit Risk Management preferred.
Knowledge of contemporary supervised and unsupervised data mining techniques a plus.


Required Skills and Abilities:

Motivation Skills - History of achieving aggressive organizational goals and objectives, conveying sense of urgency while moving beyond challenges and obstacles.
Thinking and Administrative Skills - Solid analytical and problem solving skills. Ability to analyze trends and suggest solutions to challenges.
Achieve Successful Results – Takes the initiative to get things done.
Demonstrates Adaptability – Works effectively in the face of stress, ambiguity, difficult situations and shifting priorities.
Innovates – Challenges the status quo thinking to generate new ideas; takes open minded approach to situations.
Communication Skills - Refined written and verbal communication skills. Ability to foster open communications, listen effectively and build strong partnership networks.
Technological Competence – Extensive knowledge of R, Python, Scala, Java, SAS, MATLAB, SQL, and/or SPSS and risk management technology with the ability to leverage such tools to improve the organization’s decision making criteria.

Qualifications
Skills
Behaviors
:
Motivations
:
Education
Experience
Licenses & Certifications",1
"PwC Labs is focused on standardizing, automating, delivering tools and processes and exploring emerging technologies that drive efficiency and enable our people to reimagine the possible. Process improvement, transformation, effective use of innovative technology and data & analytics, and leveraging alternative delivery solutions are key areas of focus to drive additional value for our firm. The Automation Lab within PwC Labs is focused on implementing intelligent process automation solutions that will impact the overall efficiency and effectiveness of our business processes across Tax, Assurance, Advisory, and Internal Firm Services. Process improvement, transformation, system implementation, effective use of technology and data & analytics, and leveraging alternative delivery solutions are key areas of focus to drive additional value to our firm.
To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be an authentic and inclusive leader, at all grades/levels and in all lines of service. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.
As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:
Use feedback and reflection to develop self awareness, personal strengths and address development areas.
Delegate to others to provide stretch opportunities and coach to help deliver results.
Develop new ideas and propose innovative solutions to problems.
Use a broad range of tools and techniques to extract insights from from current trends in business area.
Review your work and that of others for quality, accuracy and relevance.
Share relevant thought leadership.
Use straightforward communication, in a structured way, when influencing others.
Able to read situations and modify behavior to build quality, diverse relationships.
Uphold the firm's code of ethics and business conduct.
Job Requirements and Preferences:

Basic Qualifications:

Minimum Degree Required:
Bachelor Degree

Additional Educational Requirements:
In lieu of a Bachelor Degree, 12 years of professional experience involving technology-focused process improvements, transformations, and/or system implementations.
Minimum Years of Experience:
3 year(s)

Preferred Qualifications:

Degree Preferred:
Master Degree

Preferred Fields of Study:
Computer and Information Science, Computer and Information Science & Accounting, Economics, Economics and Finance, Economics and Finance & Technology, Engineering, Operations Management/Research, Statistics


Preferred Knowledge/Skills:
Demonstrates thorough knowledge and/or a proven record of success in the following areas:
New technology learning and quickly evaluating their technical and commercial viability;
Machine learning techniques for addressing a variety of problems (e.g. consumer segmentation, revenue forecasting, image classification, etc.); and,
Machine learning algorithms (e.g. k-nearest neighbors, random forests, ensemble methods, deep neural networks, etc.) and when it is appropriate to use each technique.
Demonstrates thorough abilities and/or a proven record of success as a team leader including the following areas:
Building machine learning models and systems, interpreting their output, and communicating the results;
Moving models from development to production; and,
Conducting research in a lab and publishing work
Demonstrates thorough abilities and/or a proven record of success with a subset of the following technologies:
Programming including Python, R, Java, JavaScript, C++, Unix Hardware, sensors, robotics, GPU enabled machine learning, FPGAs, and Raspberry Pis, etc.;
Data Storage Technologies including SQL, NoSQL, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);
Data Processing Tools including Python (Numpy, Pandas, etc.), Spark, and cloud-based solutions such as GCP DataFlow;
Machine Learning Libraries including Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, and Spark MLlib;
Visualization including Python (Matplotlib, Seaborn, bokeh, etc.), and JavaScript (d3); and,
Productionization and containerization technologies including GitHub, Flask, Docker, and Kubernetes.
All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.",1
"Job Description:
Collaborate with Innovative 3Mers Around the World
Choosing where to start and grow your career has a major impact on your professional and personal life, so it’s equally important you know that the company that you choose to work at, and its leaders, will support and guide you. With a diversity of people, global locations, technologies and products, 3M is a place where you can collaborate with 93,000 other curious, creative 3Mers.
“3M’s culture is driven by curious, spirited and collaborative people who are constantly asking ‘What if?’ And the many talents of 3Mers around the globe have me incredibly excited about what’s to come next.” – Kristen Ludgate, senior vice president of Human Resources at 3M
This position provides an opportunity to transition from other private, public, government or military environments to a 3M career.
The Impact You’ll Make in this Role
As a Data Engineer, you will have the opportunity to tap into your curiosity and collaborate with some of the most innovative and diverse people around the world. Here, you will make an impact by:
Developing, maintaining, and supporting applications on Cloud-based platforms
Leveraging Agile, CI/CD and DevOps methodologies to deliver high quality product on-time
Building Automation tools to improve cycle time
Your Skills and Expertise
To set you up for success in this role from day one, 3M is looking for candidates who must have the following qualifications:
Bachelor’s degree or higher (completed and verified prior to start) from an accredited institution
One (1) year of Software Development Lifecycle experience in a private, public, government or military environment
Additional qualifications that could help you succeed even further in this role include:
Experience developing commercial software using Object Oriented Technologies
Platform development experience using Azure
Database/Data Warehouse experience
Knowledge React or other UI building tools
Location: Maplewood, MN and may consider remote U.S. work location
Travel: May include up to 10% domestic
Relocation Assistance: Not authorized
Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).
Supporting Your Well-being
3M offers many programs to help you live your best life – both physically and financially. To ensure competitive pay and benefits, 3M regularly benchmarks with other companies that are comparable in size and scope.
Resources for You
For more details on what happens before, during and after the interview process, check out the Insights for Candidates page at 3M.com/careers.
Learn more about 3M’s creative solutions to the world’s problems at www.3M.com or on Twitter @3M.
Responsibilities of this position include that corporate policies, procedures and security standards are complied with while performing assigned duties.
3M is an equal opportunity employer. 3M will not discriminate against any applicant for employment on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or veteran status.
Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.
3M Global Terms of Use and Privacy Statement

Carefully read these Terms of Use before using this website. Your access to and use of this website and application for a job at 3M are conditioned on your acceptance and compliance with these terms.",3
"Senior Data Scientist-Job DescriptionSentryHealth is searching for a strategic and inquisitive Senior Data Scientist to develop and run with data-centered projects. In keeping with this overarching aim, the Senior Data Scientist will be required to outline work requirements, assign tasks to junior staff, and monitor performance within the team. You should also harness your mastery of Data Science to consult on various aspects of these and other projects. As an experienced Senior Data Scientist, you will play an integral role to support our business operations by providing relevant, timely, and actionable insights to care teams and teammates-helping them make better, more informed decisions. This is accomplished by applying advanced analytic techniques to large integrated data sets and rendering outputs to users through data visualization tools.To be successful as a Senior Data Scientist, you should use data to ultimately inform and promote the company’s expansion. First-rate Senior Data Scientists will assume a prominent role in the development of junior staff.You will be joining an innovative team that is passionate about using advanced analytics to improve healthcare outcomes for our clients.Senior Data Scientist Responsibilities· Aggregate data and generate reports for a variety of internal and external stakeholders.· Collating and cleaning data from various entities for later use by Junior Data Scientists.· Delegating tasks to Junior Data Scientists in order to realize the successful completion of projects.· Monitoring the performance of Junior Data Scientists and providing them with practical guidance, as needed.· Analyze numerous metrics, including historical trends, and breakdowns by sub-categories and segments.· Utilize established data-gather and modeling strategies in working with diverse data types, including clinical values, demographic data, medical and financial information.· Generate program participant eligibility using medical claim data provided by data aggregators, clients, and other third-party sources.· Acquire and assemble datasets from a variety of sources, ensuring data integrity and security.· Identify issues, including systematic issues, with production and maintenance of data.· Build and maintain complex spreadsheets, documenting sources and methodologies.· Suggesting ways in which insights obtained might be used to inform business strategies.· Staying informed about developments in Data Science and adjacent fields to ensure that outputs are always relevant.Required Qualifications: Experience in developing machine learning models and applying advanced analytics solutions to solve complex business problemsExperience with programming languages including: R, Python, Scala, JavaProficiency with SQL programmingExperience constructing and executing queries to extract data in support of EDA and model developmentProficiency with statistical software packages including: SAS, SPSS Modeler, R, WEKA, or equivalentExperience with unsupervised and supervised machine learning techniques and methodsExperience working with large-scale (e.g., terabyte and petabyte) unstructured and structured data sets and databasesExperience performing data mining, analysis, and training set constructionBachelors Degree (required) or Masters Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experienceAbility to relay insights in layman’s terms, such that these can be used to inform business decisions.Outstanding supervision and mentorship abilities.Capacity to foster a healthy, stimulating work environment that frequently harnesses teamwork.Sentry Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The noise level in the work environment is usually quiet, as this is a business office environment.Job Type: Full-timeSalary: $75,000.00 to $100,000.00 /yearExperience:data analyst/scientist: 2 years (Preferred)Education:Bachelor's (Required)Benefits:Health insuranceDental insuranceVision insuranceRetirement planPaid time offWork from homeSchedule:Monday to FridayCompany's website:https://www.sentryhealth.com/Benefit Conditions:Waiting period may applyWork Remotely:Yes",1
